{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Q-Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\['\n",
      "C:\\Users\\yahya\\AppData\\Local\\Temp\\ipykernel_8924\\1333411057.py:4: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n### What is Q-Learning?\\n\\nQ-Learning is a model-free reinforcement learning algorithm used to find the optimal action-selection policy for a given finite Markov Decision Process (MDP). It is based on the concept of learning the Q-value, which represents the expected utility of taking a certain action in a given state, and following the optimal policy thereafter.\\n\\nThe Q-value is updated iteratively using the following update rule:\\n\\n\\\\[\\nQ(s_t, a_t) \\\\leftarrow Q(s_t, a_t) + \\x07lpha \\\\left( R_t + \\\\gamma \\\\max_{a} Q(s_{t+1}, a) - Q(s_t, a_t) \\right)\\n\\\\]\\n\\nWhere:\\n- \\\\( Q(s_t, a_t) \\\\): Current Q-value for state \\\\( s_t \\\\) and action \\\\( a_t \\\\).\\n- \\\\( \\x07lpha \\\\): Learning rate, which determines how much new information overrides the old information.\\n- \\\\( R_t \\\\): Reward received after taking action \\\\( a_t \\\\) in state \\\\( s_t \\\\).\\n- \\\\( \\\\gamma \\\\): Discount factor, which determines the importance of future rewards.\\n- \\\\( \\\\max_{a} Q(s_{t+1}, a) \\\\): Maximum Q-value for the next state \\\\( s_{t+1} \\\\) over all possible actions.\\n\\nThe goal of Q-Learning is to iteratively update the Q-values until they converge to the optimal Q-values, which can then be used to derive the optimal policy.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Introduction to Q-Learning\n",
    "\n",
    "# Markdown cell explaining the Q-Learning algorithm\n",
    "\"\"\"\n",
    "### What is Q-Learning?\n",
    "\n",
    "Q-Learning is a model-free reinforcement learning algorithm used to find the optimal action-selection policy for a given finite Markov Decision Process (MDP). It is based on the concept of learning the Q-value, which represents the expected utility of taking a certain action in a given state, and following the optimal policy thereafter.\n",
    "\n",
    "The Q-value is updated iteratively using the following update rule:\n",
    "\n",
    "\\[\n",
    "Q(s_t, a_t) \\leftarrow Q(s_t, a_t) + \\alpha \\left( R_t + \\gamma \\max_{a} Q(s_{t+1}, a) - Q(s_t, a_t) \\right)\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( Q(s_t, a_t) \\): Current Q-value for state \\( s_t \\) and action \\( a_t \\).\n",
    "- \\( \\alpha \\): Learning rate, which determines how much new information overrides the old information.\n",
    "- \\( R_t \\): Reward received after taking action \\( a_t \\) in state \\( s_t \\).\n",
    "- \\( \\gamma \\): Discount factor, which determines the importance of future rewards.\n",
    "- \\( \\max_{a} Q(s_{t+1}, a) \\): Maximum Q-value for the next state \\( s_{t+1} \\) over all possible actions.\n",
    "\n",
    "The goal of Q-Learning is to iteratively update the Q-values until they converge to the optimal Q-values, which can then be used to derive the optimal policy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Importing Libraries\n",
    "\n",
    "In this section, we import the necessary libraries for implementing the Q-Learning algorithm:\n",
    "\n",
    "- **NumPy**: A powerful library for numerical computations. It is used for handling arrays, performing mathematical operations, and managing the Q-value table efficiently.\n",
    "- **Matplotlib**: A library for creating visualizations. It will be used to plot the results and visualize the learning process.\n",
    "\n",
    "These libraries are essential for implementing and analyzing the Q-Learning algorithm effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Grid Graph\n",
    "Explain the grid graph structure, where each state is a node, and edges represent possible actions with directions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Grid Graph\n",
    "\n",
    "The grid graph represents the environment in which the agent operates. Each state in the grid is represented as a node, and the edges between nodes represent possible actions (e.g., moving up, down, left, or right). The graph is defined as a dictionary where:\n",
    "- Keys are the states (nodes) represented as strings.\n",
    "- Values are lists of tuples, where each tuple contains:\n",
    "  - The neighboring state (node) the agent can move to.\n",
    "  - The action (direction) required to move to that neighboring state.\n",
    "\n",
    "This structure allows us to model the environment and define the possible transitions between states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Grid Graph\n",
    "\n",
    "grid_graph = {\n",
    "    \"1\": [(\"2\", \"right\"), (\"6\", \"down\")],\n",
    "    \"2\": [(\"1\", \"left\"), (\"3\", \"right\"), (\"7\", \"down\")],\n",
    "    \"3\": [(\"2\", \"left\"), (\"4\", \"right\"), (\"8\", \"down\")],\n",
    "    \"4\": [(\"3\", \"left\"), (\"5\", \"right\"), (\"9\", \"down\")],\n",
    "    \"5\": [(\"4\", \"left\"), (\"10\", \"down\")],\n",
    "\n",
    "    \"6\": [(\"1\", \"up\"), (\"7\", \"right\"), (\"11\", \"down\")],\n",
    "    \"7\": [(\"2\", \"up\"), (\"6\", \"left\"), (\"8\", \"right\"), (\"12\", \"down\")],\n",
    "    \"8\": [(\"3\", \"up\"), (\"7\", \"left\"), (\"9\", \"right\"), (\"13\", \"down\")],\n",
    "    \"9\": [(\"4\", \"up\"), (\"8\", \"left\"), (\"10\", \"right\"), (\"14\", \"down\")],\n",
    "    \"10\": [(\"5\", \"up\"), (\"9\", \"left\"), (\"15\", \"down\")],\n",
    "\n",
    "    \"11\": [(\"6\", \"up\"), (\"12\", \"right\"), (\"16\", \"down\")],\n",
    "    \"12\": [(\"7\", \"up\"), (\"11\", \"left\"), (\"13\", \"right\"), (\"17\", \"down\")],\n",
    "    \"13\": [(\"8\", \"up\"), (\"12\", \"left\"), (\"14\", \"right\"), (\"18\", \"down\")],\n",
    "    \"14\": [(\"9\", \"up\"), (\"13\", \"left\"), (\"15\", \"right\"), (\"19\", \"down\")],\n",
    "    \"15\": [(\"10\", \"up\"), (\"14\", \"left\"), (\"20\", \"down\")],\n",
    "\n",
    "    \"16\": [(\"11\", \"up\"), (\"17\", \"right\"), (\"21\", \"down\")],\n",
    "    \"17\": [(\"12\", \"up\"), (\"16\", \"left\"), (\"18\", \"right\"), (\"22\", \"down\")],\n",
    "    \"18\": [(\"13\", \"up\"), (\"17\", \"left\"), (\"19\", \"right\"), (\"23\", \"down\")],\n",
    "    \"19\": [(\"14\", \"up\"), (\"18\", \"left\"), (\"20\", \"right\"), (\"24\", \"down\")],\n",
    "    \"20\": [(\"15\", \"up\"), (\"19\", \"left\"), (\"25\", \"down\")],\n",
    "\n",
    "    \"21\": [(\"16\", \"up\"), (\"22\", \"right\")],\n",
    "    \"22\": [(\"17\", \"up\"), (\"21\", \"left\"), (\"23\", \"right\")],\n",
    "    \"23\": [(\"18\", \"up\"), (\"22\", \"left\"), (\"24\", \"right\")],\n",
    "    \"24\": [(\"19\", \"up\"), (\"23\", \"left\"), (\"25\", \"right\")],\n",
    "    \"25\": [(\"20\", \"up\"), (\"24\", \"left\")]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Q-States and Rewards\n",
    "Add a markdown cell explaining the initialization of Q-values for each state-action pair and the reward structure, including penalties and goal rewards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Q-Values and Rewards\n",
    "\n",
    "In this section, we initialize the Q-values and rewards for each state in the grid environment:\n",
    "\n",
    "- **Q-Values**: Represent the expected utility of taking a specific action in a given state. Initially, all Q-values are set to 0 for every state-action pair.\n",
    "- **Rewards**: Define the immediate reward received upon entering a state. Most states have a default reward of -1 to encourage the agent to find the shortest path to the goal. Special states include:\n",
    "  - **State 0**: A penalty state with a reward of -10.\n",
    "  - **State 25**: The goal state with a reward of +10.\n",
    "\n",
    "This setup ensures that the agent is incentivized to reach the goal state while avoiding unnecessary steps or penalties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Q-States and Rewards\n",
    "\n",
    "\n",
    "# Initialize Q-values for each state-action pair\n",
    "Q_states = {str(i): {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0} for i in range(1, 26)}\n",
    "\n",
    "# Define rewards for each state\n",
    "rewards = {str(i): -1 for i in range(1, 26)}\n",
    "rewards[\"0\"] = -10  # Penalty state\n",
    "rewards[\"25\"] = 10  # Goal state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "Explain the purpose of helper functions for retrieving neighbor states, getting and setting Q-values, and fetching rewards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "This section defines helper functions that are essential for the Q-Learning algorithm. These functions include:\n",
    "\n",
    "1. **`get_neighbor_states(state)`**: Retrieves the neighboring states and possible actions for a given state.\n",
    "2. **`get_state_Q(state, action)`**: Fetches the Q-value for a specific state-action pair.\n",
    "3. **`set_state_Q(state, action, new_value)`**: Updates the Q-value for a specific state-action pair.\n",
    "4. **`get_reward(state)`**: Returns the reward associated with a given state.\n",
    "\n",
    "These functions abstract the operations on the grid graph, Q-values, and rewards, making the implementation modular and easier to understand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "# Function to retrieve neighboring states and actions\n",
    "def get_neighbor_states(state: str) -> list[tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Retrieves the neighboring states and possible actions for a given state.\n",
    "\n",
    "    Args:\n",
    "        state (str): The current state.\n",
    "\n",
    "    Returns:\n",
    "        list[tuple[str, str]]: A list of tuples where each tuple contains:\n",
    "            - The neighboring state.\n",
    "            - The action required to move to that state.\n",
    "    \"\"\"\n",
    "    return grid_graph[state]\n",
    "\n",
    "# Function to get the Q-value for a specific state-action pair\n",
    "def get_state_Q(state: str, action: str) -> int:\n",
    "    \"\"\"\n",
    "    Fetches the Q-value for a specific state-action pair.\n",
    "\n",
    "    Args:\n",
    "        state (str): The current state.\n",
    "        action (str): The action to be taken.\n",
    "\n",
    "    Returns:\n",
    "        int: The Q-value for the given state-action pair.\n",
    "    \"\"\"\n",
    "    return Q_states[state][action]\n",
    "\n",
    "# Function to set the Q-value for a specific state-action pair\n",
    "def set_state_Q(state: str, action: str, new_value: float) -> None:\n",
    "    \"\"\"\n",
    "    Updates the Q-value for a specific state-action pair.\n",
    "\n",
    "    Args:\n",
    "        state (str): The current state.\n",
    "        action (str): The action to be taken.\n",
    "        new_value (float): The new Q-value to be set.\n",
    "    \"\"\"\n",
    "    Q_states[state][action] = new_value\n",
    "\n",
    "# Function to get the reward for a specific state\n",
    "def get_reward(state: str) -> int:\n",
    "    \"\"\"\n",
    "    Returns the reward associated with a given state.\n",
    "\n",
    "    Args:\n",
    "        state (str): The current state.\n",
    "\n",
    "    Returns:\n",
    "        int: The reward for the given state.\n",
    "    \"\"\"\n",
    "    return rewards[state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Value Update Function\n",
    "Add a markdown cell explaining the Q-value update function, including the role of learning rate, discount factor, and step penalty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Value Update Function\n",
    "\n",
    "The Q-value update function is a critical component of the Q-Learning algorithm. It updates the Q-value for a given state-action pair based on the reward received and the maximum Q-value of the next state. The update rule is as follows:\n",
    "\n",
    "$$\n",
    "Q(s_t, a_t) \\leftarrow Q(s_t, a_t) + \\alpha \\left( R_t + \\gamma \\max_{a} Q(s_{t+1}, a) - Q(s_t, a_t) \\right)\n",
    "$$\n",
    "\n",
    "#### Components:\n",
    "- **Learning Rate ($ \\alpha $)**: Determines how much the new information overrides the old information. A higher value means the agent learns faster but may overshoot the optimal value.\n",
    "- **Discount Factor ($ \\gamma $)**: Determines the importance of future rewards. A value close to 1 emphasizes long-term rewards, while a value close to 0 focuses on immediate rewards.\n",
    "- **Step Penalty**: An additional penalty applied to discourage unnecessary steps, encouraging the agent to find the shortest path to the goal.\n",
    "\n",
    "This function ensures that the agent learns the optimal policy by iteratively updating the Q-values based on the observed rewards and transitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Value Update Function\n",
    "\n",
    "\n",
    "def get_Q_update(\n",
    "    state_Q: float,\n",
    "    state_reward: float,\n",
    "    neighbor_states: list[str],\n",
    "    learning_rate: float = 0.5,\n",
    "    discount_factor: float = 0.5,\n",
    "    step_penalty: float = 0\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Updates the Q-value for a given state-action pair.\n",
    "\n",
    "    Args:\n",
    "        state_Q (float): Current Q-value of the state-action pair.\n",
    "        state_reward (float): Reward received for the current state.\n",
    "        neighbor_states (list[str]): List of neighboring states and actions.\n",
    "        learning_rate (float, optional): Learning rate (alpha). Defaults to 0.5.\n",
    "        discount_factor (float, optional): Discount factor (gamma). Defaults to 0.5.\n",
    "        step_penalty (float, optional): Penalty for taking a step. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        float: Updated Q-value for the state-action pair.\n",
    "    \"\"\"\n",
    "    # Calculate the maximum Q-value among the neighboring states\n",
    "    neighbor_states_Q = map(lambda x: get_state_Q(*x), neighbor_states)\n",
    "    \n",
    "    # Apply the Q-value update formula\n",
    "    return state_Q + learning_rate * (\n",
    "        (state_reward + step_penalty) + discount_factor * max(neighbor_states_Q) - state_Q\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighbor Q-Values and Next State Selection\n",
    "Explain the logic for calculating neighbor Q-values and selecting the next state based on the highest Q-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Neighbor Q-Values\n",
    "\n",
    "In this section, we calculate the Q-values of all neighboring states for a given current state. This helps the agent evaluate the potential outcomes of each possible action. The function `get_neighbor_states_Q` retrieves the Q-values for all neighboring states and their corresponding actions.\n",
    "\n",
    "#### Formula:\n",
    "For each neighboring state \\( s' \\) and action \\( a \\), the Q-value is given by:\n",
    "\\[\n",
    "Q(s, a) = Q_{\\text{states}}[s][a]\n",
    "\\]\n",
    "\n",
    "This step is crucial for determining the best action to take from the current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neighbor Q-Values \n",
    "\n",
    "def get_neighbor_states_Q(current_state: str, neighbor_states: list[tuple[str, str]]) -> list[float]:\n",
    "    \"\"\"\n",
    "    Retrieves the Q-values for all neighboring states and actions.\n",
    "\n",
    "    Args:\n",
    "        current_state (str): The current state.\n",
    "        neighbor_states (list[tuple[str, str]]): List of neighboring states and actions.\n",
    "\n",
    "    Returns:\n",
    "        list[float]: List of Q-values for the neighboring states and actions.\n",
    "    \"\"\"\n",
    "    return list(map(lambda x: get_state_Q(current_state, x[1]), neighbor_states))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the Next State\n",
    "\n",
    "After calculating the Q-values of all neighboring states, the agent selects the next state based on the action with the highest Q-value. The function `get_next_state` identifies the best action and its corresponding state.\n",
    "\n",
    "#### Logic:\n",
    "1. Compute the Q-values for all neighboring states.\n",
    "2. Identify the action with the maximum Q-value.\n",
    "3. Return the corresponding neighboring state and action.\n",
    "\n",
    "This ensures that the agent follows a greedy policy to maximize its expected reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next State Selection\n",
    "\n",
    "def get_next_state(current_state: str, neighbor_states: list[tuple[str, str]]) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Selects the next state based on the highest Q-value among neighboring states.\n",
    "\n",
    "    Args:\n",
    "        current_state (str): The current state.\n",
    "        neighbor_states (list[tuple[str, str]]): List of neighboring states and actions.\n",
    "\n",
    "    Returns:\n",
    "        tuple[str, str]: The next state and the action leading to it.\n",
    "    \"\"\"\n",
    "    neighbor_states_Q = get_neighbor_states_Q(current_state, neighbor_states)\n",
    "    max_index = np.argmax(neighbor_states_Q)\n",
    "    return neighbor_states[max_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Q-Learning Loop\n",
    "\n",
    "\n",
    "### Main Q-Learning Loop\n",
    "\n",
    "This section implements the main loop of the Q-Learning algorithm. The loop iteratively updates the Q-values, selects actions, and transitions between states until the goal state is reached or a maximum number of iterations is exceeded.\n",
    "\n",
    "#### Steps:\n",
    "1. **Initialization**: Start from an initial state (e.g., state \"1\").\n",
    "2. **Neighbor States**: Retrieve the neighboring states and their Q-values.\n",
    "3. **Action Selection**: Choose the next action based on the highest Q-value (greedy policy).\n",
    "4. **Q-Value Update**: Update the Q-value of the current state-action pair using the Q-Learning update rule.\n",
    "5. **Transition**: Move to the next state and repeat the process.\n",
    "6. **Stopping Condition**: Stop when the goal state is reached or the maximum number of iterations is reached.\n",
    "\n",
    "This loop ensures that the agent learns the optimal policy by exploring the environment and updating its Q-values based on observed rewards and transitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "\tCurrent state: 1\n",
      "\tNeighbor states: [('2', 'right'), ('6', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0]\n",
      "\tNext action: \"right\" to state 2 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 2:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0]\n",
      "\tNext action: \"left\" to state 1 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 3:\n",
      "\tCurrent state: 1\n",
      "\tNeighbor states: [('2', 'right'), ('6', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 6 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 4:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0]\n",
      "\tNext action: \"up\" to state 1 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 5:\n",
      "\tCurrent state: 1\n",
      "\tNeighbor states: [('2', 'right'), ('6', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"right\" to state 2 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 6:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0]\n",
      "\tNext action: \"right\" to state 3 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 7:\n",
      "\tCurrent state: 3\n",
      "\tNeighbor states: [('2', 'left'), ('4', 'right'), ('8', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0]\n",
      "\tNext action: \"left\" to state 2 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 8:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 7 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 9:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0, 0]\n",
      "\tNext action: \"up\" to state 2 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 10:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"left\" to state 1 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 11:\n",
      "\tCurrent state: 1\n",
      "\tNeighbor states: [('2', 'right'), ('6', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 6 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 12:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0]\n",
      "\tNext action: \"right\" to state 7 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 13:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0, 0]\n",
      "\tNext action: \"left\" to state 6 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 14:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 11 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 15:\n",
      "\tCurrent state: 11\n",
      "\tNeighbor states: [('6', 'up'), ('12', 'right'), ('16', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0]\n",
      "\tNext action: \"up\" to state 6 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 16:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"up\" to state 1 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 17:\n",
      "\tCurrent state: 1\n",
      "\tNeighbor states: [('2', 'right'), ('6', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"right\" to state 2 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.107\n",
      "Step 18:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"right\" to state 3 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 19:\n",
      "\tCurrent state: 3\n",
      "\tNeighbor states: [('2', 'left'), ('4', 'right'), ('8', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0]\n",
      "\tNext action: \"right\" to state 4 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 20:\n",
      "\tCurrent state: 4\n",
      "\tNeighbor states: [('3', 'left'), ('5', 'right'), ('9', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0]\n",
      "\tNext action: \"left\" to state 3 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 21:\n",
      "\tCurrent state: 3\n",
      "\tNeighbor states: [('2', 'left'), ('4', 'right'), ('8', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 8 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 22:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0, 0]\n",
      "\tNext action: \"up\" to state 3 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 23:\n",
      "\tCurrent state: 3\n",
      "\tNeighbor states: [('2', 'left'), ('4', 'right'), ('8', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"left\" to state 2 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 24:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 7 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 25:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0, 0]\n",
      "\tNext action: \"right\" to state 8 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 26:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0, 0]\n",
      "\tNext action: \"left\" to state 7 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 27:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 12 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 28:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0, 0]\n",
      "\tNext action: \"up\" to state 7 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 29:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"up\" to state 2 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 30:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"left\" to state 1 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 31:\n",
      "\tCurrent state: 1\n",
      "\tNeighbor states: [('2', 'right'), ('6', 'down')]\n",
      "\tNeighbor states Q-values: [-1.107, -0.7649999999999999]\n",
      "\tNext action: \"down\" to state 6 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.107\n",
      "Step 32:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"right\" to state 7 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 33:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"left\" to state 6 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 34:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 11 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 35:\n",
      "\tCurrent state: 11\n",
      "\tNeighbor states: [('6', 'up'), ('12', 'right'), ('16', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0]\n",
      "\tNext action: \"right\" to state 12 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 36:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0, 0]\n",
      "\tNext action: \"left\" to state 11 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 37:\n",
      "\tCurrent state: 11\n",
      "\tNeighbor states: [('6', 'up'), ('12', 'right'), ('16', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 16 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 38:\n",
      "\tCurrent state: 16\n",
      "\tNeighbor states: [('11', 'up'), ('17', 'right'), ('21', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0]\n",
      "\tNext action: \"up\" to state 11 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 39:\n",
      "\tCurrent state: 11\n",
      "\tNeighbor states: [('6', 'up'), ('12', 'right'), ('16', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"up\" to state 6 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 40:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"up\" to state 1 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 41:\n",
      "\tCurrent state: 1\n",
      "\tNeighbor states: [('2', 'right'), ('6', 'down')]\n",
      "\tNeighbor states Q-values: [-1.107, -1.107]\n",
      "\tNext action: \"right\" to state 2 with Q-value = -1.107 and reward = -1\n",
      "\tUpdated Q-value: -1.43145\n",
      "Step 42:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"right\" to state 3 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 43:\n",
      "\tCurrent state: 3\n",
      "\tNeighbor states: [('2', 'left'), ('4', 'right'), ('8', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"right\" to state 4 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 44:\n",
      "\tCurrent state: 4\n",
      "\tNeighbor states: [('3', 'left'), ('5', 'right'), ('9', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0]\n",
      "\tNext action: \"right\" to state 5 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 45:\n",
      "\tCurrent state: 5\n",
      "\tNeighbor states: [('4', 'left'), ('10', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0]\n",
      "\tNext action: \"left\" to state 4 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 46:\n",
      "\tCurrent state: 4\n",
      "\tNeighbor states: [('3', 'left'), ('5', 'right'), ('9', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 9 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 47:\n",
      "\tCurrent state: 9\n",
      "\tNeighbor states: [('4', 'up'), ('8', 'left'), ('10', 'right'), ('14', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0, 0]\n",
      "\tNext action: \"up\" to state 4 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 48:\n",
      "\tCurrent state: 4\n",
      "\tNeighbor states: [('3', 'left'), ('5', 'right'), ('9', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"left\" to state 3 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 49:\n",
      "\tCurrent state: 3\n",
      "\tNeighbor states: [('2', 'left'), ('4', 'right'), ('8', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 8 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 50:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0, 0]\n",
      "\tNext action: \"right\" to state 9 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 51:\n",
      "\tCurrent state: 9\n",
      "\tNeighbor states: [('4', 'up'), ('8', 'left'), ('10', 'right'), ('14', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0, 0]\n",
      "\tNext action: \"left\" to state 8 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 52:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 13 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 53:\n",
      "\tCurrent state: 13\n",
      "\tNeighbor states: [('8', 'up'), ('12', 'left'), ('14', 'right'), ('18', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0, 0]\n",
      "\tNext action: \"up\" to state 8 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 54:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"up\" to state 3 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 55:\n",
      "\tCurrent state: 3\n",
      "\tNeighbor states: [('2', 'left'), ('4', 'right'), ('8', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"left\" to state 2 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.107\n",
      "Step 56:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.7649999999999999]\n",
      "\tNext action: \"down\" to state 7 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 57:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"right\" to state 8 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 58:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"left\" to state 7 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 59:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 12 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 60:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0, 0]\n",
      "\tNext action: \"right\" to state 13 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 61:\n",
      "\tCurrent state: 13\n",
      "\tNeighbor states: [('8', 'up'), ('12', 'left'), ('14', 'right'), ('18', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0, 0]\n",
      "\tNext action: \"left\" to state 12 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 62:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 17 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 63:\n",
      "\tCurrent state: 17\n",
      "\tNeighbor states: [('12', 'up'), ('16', 'left'), ('18', 'right'), ('22', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0, 0]\n",
      "\tNext action: \"up\" to state 12 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 64:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"up\" to state 7 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 65:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"up\" to state 2 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 66:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"left\" to state 1 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 67:\n",
      "\tCurrent state: 1\n",
      "\tNeighbor states: [('2', 'right'), ('6', 'down')]\n",
      "\tNeighbor states Q-values: [-1.43145, -1.107]\n",
      "\tNext action: \"down\" to state 6 with Q-value = -1.107 and reward = -1\n",
      "\tUpdated Q-value: -1.43145\n",
      "Step 68:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"right\" to state 7 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 69:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"left\" to state 6 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 70:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.7649999999999999]\n",
      "\tNext action: \"down\" to state 11 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 71:\n",
      "\tCurrent state: 11\n",
      "\tNeighbor states: [('6', 'up'), ('12', 'right'), ('16', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"right\" to state 12 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 72:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"left\" to state 11 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 73:\n",
      "\tCurrent state: 11\n",
      "\tNeighbor states: [('6', 'up'), ('12', 'right'), ('16', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 16 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 74:\n",
      "\tCurrent state: 16\n",
      "\tNeighbor states: [('11', 'up'), ('17', 'right'), ('21', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0]\n",
      "\tNext action: \"right\" to state 17 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 75:\n",
      "\tCurrent state: 17\n",
      "\tNeighbor states: [('12', 'up'), ('16', 'left'), ('18', 'right'), ('22', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0, 0]\n",
      "\tNext action: \"left\" to state 16 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 76:\n",
      "\tCurrent state: 16\n",
      "\tNeighbor states: [('11', 'up'), ('17', 'right'), ('21', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 21 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 77:\n",
      "\tCurrent state: 21\n",
      "\tNeighbor states: [('16', 'up'), ('22', 'right')]\n",
      "\tNeighbor states Q-values: [0, 0]\n",
      "\tNext action: \"up\" to state 16 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 78:\n",
      "\tCurrent state: 16\n",
      "\tNeighbor states: [('11', 'up'), ('17', 'right'), ('21', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"up\" to state 11 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 79:\n",
      "\tCurrent state: 11\n",
      "\tNeighbor states: [('6', 'up'), ('12', 'right'), ('16', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"up\" to state 6 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.107\n",
      "Step 80:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"up\" to state 1 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 81:\n",
      "\tCurrent state: 1\n",
      "\tNeighbor states: [('2', 'right'), ('6', 'down')]\n",
      "\tNeighbor states Q-values: [-1.43145, -1.43145]\n",
      "\tNext action: \"right\" to state 2 with Q-value = -1.43145 and reward = -1\n",
      "\tUpdated Q-value: -1.7180999999999997\n",
      "Step 82:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"right\" to state 3 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 83:\n",
      "\tCurrent state: 3\n",
      "\tNeighbor states: [('2', 'left'), ('4', 'right'), ('8', 'down')]\n",
      "\tNeighbor states Q-values: [-1.107, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"right\" to state 4 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.107\n",
      "Step 84:\n",
      "\tCurrent state: 4\n",
      "\tNeighbor states: [('3', 'left'), ('5', 'right'), ('9', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"right\" to state 5 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 85:\n",
      "\tCurrent state: 5\n",
      "\tNeighbor states: [('4', 'left'), ('10', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 10 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 86:\n",
      "\tCurrent state: 10\n",
      "\tNeighbor states: [('5', 'up'), ('9', 'left'), ('15', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0]\n",
      "\tNext action: \"up\" to state 5 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 87:\n",
      "\tCurrent state: 5\n",
      "\tNeighbor states: [('4', 'left'), ('10', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"left\" to state 4 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 88:\n",
      "\tCurrent state: 4\n",
      "\tNeighbor states: [('3', 'left'), ('5', 'right'), ('9', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 9 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 89:\n",
      "\tCurrent state: 9\n",
      "\tNeighbor states: [('4', 'up'), ('8', 'left'), ('10', 'right'), ('14', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0, 0]\n",
      "\tNext action: \"right\" to state 10 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 90:\n",
      "\tCurrent state: 10\n",
      "\tNeighbor states: [('5', 'up'), ('9', 'left'), ('15', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0]\n",
      "\tNext action: \"left\" to state 9 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 91:\n",
      "\tCurrent state: 9\n",
      "\tNeighbor states: [('4', 'up'), ('8', 'left'), ('10', 'right'), ('14', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 14 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 92:\n",
      "\tCurrent state: 14\n",
      "\tNeighbor states: [('9', 'up'), ('13', 'left'), ('15', 'right'), ('19', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0, 0]\n",
      "\tNext action: \"up\" to state 9 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 93:\n",
      "\tCurrent state: 9\n",
      "\tNeighbor states: [('4', 'up'), ('8', 'left'), ('10', 'right'), ('14', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"up\" to state 4 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 94:\n",
      "\tCurrent state: 4\n",
      "\tNeighbor states: [('3', 'left'), ('5', 'right'), ('9', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"left\" to state 3 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 95:\n",
      "\tCurrent state: 3\n",
      "\tNeighbor states: [('2', 'left'), ('4', 'right'), ('8', 'down')]\n",
      "\tNeighbor states Q-values: [-1.107, -1.107, -0.7649999999999999]\n",
      "\tNext action: \"down\" to state 8 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.107\n",
      "Step 96:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"right\" to state 9 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 97:\n",
      "\tCurrent state: 9\n",
      "\tNeighbor states: [('4', 'up'), ('8', 'left'), ('10', 'right'), ('14', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"left\" to state 8 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 98:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 13 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 99:\n",
      "\tCurrent state: 13\n",
      "\tNeighbor states: [('8', 'up'), ('12', 'left'), ('14', 'right'), ('18', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0, 0]\n",
      "\tNext action: \"right\" to state 14 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 100:\n",
      "\tCurrent state: 14\n",
      "\tNeighbor states: [('9', 'up'), ('13', 'left'), ('15', 'right'), ('19', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0, 0]\n",
      "\tNext action: \"left\" to state 13 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 101:\n",
      "\tCurrent state: 13\n",
      "\tNeighbor states: [('8', 'up'), ('12', 'left'), ('14', 'right'), ('18', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 18 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 102:\n",
      "\tCurrent state: 18\n",
      "\tNeighbor states: [('13', 'up'), ('17', 'left'), ('19', 'right'), ('23', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0, 0]\n",
      "\tNext action: \"up\" to state 13 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 103:\n",
      "\tCurrent state: 13\n",
      "\tNeighbor states: [('8', 'up'), ('12', 'left'), ('14', 'right'), ('18', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"up\" to state 8 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 104:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"up\" to state 3 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 105:\n",
      "\tCurrent state: 3\n",
      "\tNeighbor states: [('2', 'left'), ('4', 'right'), ('8', 'down')]\n",
      "\tNeighbor states Q-values: [-1.107, -1.107, -1.107]\n",
      "\tNext action: \"left\" to state 2 with Q-value = -1.107 and reward = -1\n",
      "\tUpdated Q-value: -1.43145\n",
      "Step 106:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -1.13985, -0.9854999999999999]\n",
      "\tNext action: \"down\" to state 7 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 107:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"right\" to state 8 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 108:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"left\" to state 7 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 109:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.9854999999999999, -0.7649999999999999]\n",
      "\tNext action: \"down\" to state 12 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 110:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"right\" to state 13 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 111:\n",
      "\tCurrent state: 13\n",
      "\tNeighbor states: [('8', 'up'), ('12', 'left'), ('14', 'right'), ('18', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"left\" to state 12 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 112:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 17 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 113:\n",
      "\tCurrent state: 17\n",
      "\tNeighbor states: [('12', 'up'), ('16', 'left'), ('18', 'right'), ('22', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0, 0]\n",
      "\tNext action: \"right\" to state 18 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 114:\n",
      "\tCurrent state: 18\n",
      "\tNeighbor states: [('13', 'up'), ('17', 'left'), ('19', 'right'), ('23', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0, 0]\n",
      "\tNext action: \"left\" to state 17 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 115:\n",
      "\tCurrent state: 17\n",
      "\tNeighbor states: [('12', 'up'), ('16', 'left'), ('18', 'right'), ('22', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 22 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 116:\n",
      "\tCurrent state: 22\n",
      "\tNeighbor states: [('17', 'up'), ('21', 'left'), ('23', 'right')]\n",
      "\tNeighbor states Q-values: [0, 0, 0]\n",
      "\tNext action: \"up\" to state 17 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 117:\n",
      "\tCurrent state: 17\n",
      "\tNeighbor states: [('12', 'up'), ('16', 'left'), ('18', 'right'), ('22', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"up\" to state 12 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 118:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"up\" to state 7 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 119:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"up\" to state 2 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 120:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -1.13985, -1.13985]\n",
      "\tNext action: \"left\" to state 1 with Q-value = -1.13985 and reward = -1\n",
      "\tUpdated Q-value: -1.247895\n",
      "Step 121:\n",
      "\tCurrent state: 1\n",
      "\tNeighbor states: [('2', 'right'), ('6', 'down')]\n",
      "\tNeighbor states Q-values: [-1.7180999999999997, -1.43145]\n",
      "\tNext action: \"down\" to state 6 with Q-value = -1.43145 and reward = -1\n",
      "\tUpdated Q-value: -1.7180999999999997\n",
      "Step 122:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"right\" to state 7 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 123:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -0.9854999999999999, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"left\" to state 6 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 124:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -1.13985, -0.9854999999999999]\n",
      "\tNext action: \"down\" to state 11 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 125:\n",
      "\tCurrent state: 11\n",
      "\tNeighbor states: [('6', 'up'), ('12', 'right'), ('16', 'down')]\n",
      "\tNeighbor states Q-values: [-1.107, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"right\" to state 12 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.107\n",
      "Step 126:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"left\" to state 11 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 127:\n",
      "\tCurrent state: 11\n",
      "\tNeighbor states: [('6', 'up'), ('12', 'right'), ('16', 'down')]\n",
      "\tNeighbor states Q-values: [-1.107, -1.107, -0.7649999999999999]\n",
      "\tNext action: \"down\" to state 16 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.107\n",
      "Step 128:\n",
      "\tCurrent state: 16\n",
      "\tNeighbor states: [('11', 'up'), ('17', 'right'), ('21', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"right\" to state 17 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 129:\n",
      "\tCurrent state: 17\n",
      "\tNeighbor states: [('12', 'up'), ('16', 'left'), ('18', 'right'), ('22', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"left\" to state 16 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 130:\n",
      "\tCurrent state: 16\n",
      "\tNeighbor states: [('11', 'up'), ('17', 'right'), ('21', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 21 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 131:\n",
      "\tCurrent state: 21\n",
      "\tNeighbor states: [('16', 'up'), ('22', 'right')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0]\n",
      "\tNext action: \"right\" to state 22 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 132:\n",
      "\tCurrent state: 22\n",
      "\tNeighbor states: [('17', 'up'), ('21', 'left'), ('23', 'right')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0]\n",
      "\tNext action: \"left\" to state 21 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 133:\n",
      "\tCurrent state: 21\n",
      "\tNeighbor states: [('16', 'up'), ('22', 'right')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"up\" to state 16 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 134:\n",
      "\tCurrent state: 16\n",
      "\tNeighbor states: [('11', 'up'), ('17', 'right'), ('21', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"up\" to state 11 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 135:\n",
      "\tCurrent state: 11\n",
      "\tNeighbor states: [('6', 'up'), ('12', 'right'), ('16', 'down')]\n",
      "\tNeighbor states Q-values: [-1.107, -1.107, -1.107]\n",
      "\tNext action: \"up\" to state 6 with Q-value = -1.107 and reward = -1\n",
      "\tUpdated Q-value: -1.43145\n",
      "Step 136:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -1.13985, -1.13985]\n",
      "\tNext action: \"up\" to state 1 with Q-value = -1.13985 and reward = -1\n",
      "\tUpdated Q-value: -1.247895\n",
      "Step 137:\n",
      "\tCurrent state: 1\n",
      "\tNeighbor states: [('2', 'right'), ('6', 'down')]\n",
      "\tNeighbor states Q-values: [-1.7180999999999997, -1.7180999999999997]\n",
      "\tNext action: \"right\" to state 2 with Q-value = -1.7180999999999997 and reward = -1\n",
      "\tUpdated Q-value: -1.9604294999999998\n",
      "Step 138:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-1.247895, -1.13985, -1.13985]\n",
      "\tNext action: \"right\" to state 3 with Q-value = -1.13985 and reward = -1\n",
      "\tUpdated Q-value: -1.247895\n",
      "Step 139:\n",
      "\tCurrent state: 3\n",
      "\tNeighbor states: [('2', 'left'), ('4', 'right'), ('8', 'down')]\n",
      "\tNeighbor states Q-values: [-1.43145, -1.107, -1.107]\n",
      "\tNext action: \"right\" to state 4 with Q-value = -1.107 and reward = -1\n",
      "\tUpdated Q-value: -1.43145\n",
      "Step 140:\n",
      "\tCurrent state: 4\n",
      "\tNeighbor states: [('3', 'left'), ('5', 'right'), ('9', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"right\" to state 5 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 141:\n",
      "\tCurrent state: 5\n",
      "\tNeighbor states: [('4', 'left'), ('10', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 10 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 142:\n",
      "\tCurrent state: 10\n",
      "\tNeighbor states: [('5', 'up'), ('9', 'left'), ('15', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 15 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 143:\n",
      "\tCurrent state: 15\n",
      "\tNeighbor states: [('10', 'up'), ('14', 'left'), ('20', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0]\n",
      "\tNext action: \"up\" to state 10 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 144:\n",
      "\tCurrent state: 10\n",
      "\tNeighbor states: [('5', 'up'), ('9', 'left'), ('15', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"up\" to state 5 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 145:\n",
      "\tCurrent state: 5\n",
      "\tNeighbor states: [('4', 'left'), ('10', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"left\" to state 4 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.107\n",
      "Step 146:\n",
      "\tCurrent state: 4\n",
      "\tNeighbor states: [('3', 'left'), ('5', 'right'), ('9', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.7649999999999999]\n",
      "\tNext action: \"down\" to state 9 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 147:\n",
      "\tCurrent state: 9\n",
      "\tNeighbor states: [('4', 'up'), ('8', 'left'), ('10', 'right'), ('14', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"right\" to state 10 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 148:\n",
      "\tCurrent state: 10\n",
      "\tNeighbor states: [('5', 'up'), ('9', 'left'), ('15', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"left\" to state 9 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 149:\n",
      "\tCurrent state: 9\n",
      "\tNeighbor states: [('4', 'up'), ('8', 'left'), ('10', 'right'), ('14', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 14 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 150:\n",
      "\tCurrent state: 14\n",
      "\tNeighbor states: [('9', 'up'), ('13', 'left'), ('15', 'right'), ('19', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0, 0]\n",
      "\tNext action: \"right\" to state 15 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 151:\n",
      "\tCurrent state: 15\n",
      "\tNeighbor states: [('10', 'up'), ('14', 'left'), ('20', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0]\n",
      "\tNext action: \"left\" to state 14 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 152:\n",
      "\tCurrent state: 14\n",
      "\tNeighbor states: [('9', 'up'), ('13', 'left'), ('15', 'right'), ('19', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 19 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 153:\n",
      "\tCurrent state: 19\n",
      "\tNeighbor states: [('14', 'up'), ('18', 'left'), ('20', 'right'), ('24', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0, 0]\n",
      "\tNext action: \"up\" to state 14 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 154:\n",
      "\tCurrent state: 14\n",
      "\tNeighbor states: [('9', 'up'), ('13', 'left'), ('15', 'right'), ('19', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"up\" to state 9 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 155:\n",
      "\tCurrent state: 9\n",
      "\tNeighbor states: [('4', 'up'), ('8', 'left'), ('10', 'right'), ('14', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"up\" to state 4 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 156:\n",
      "\tCurrent state: 4\n",
      "\tNeighbor states: [('3', 'left'), ('5', 'right'), ('9', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"left\" to state 3 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 157:\n",
      "\tCurrent state: 3\n",
      "\tNeighbor states: [('2', 'left'), ('4', 'right'), ('8', 'down')]\n",
      "\tNeighbor states Q-values: [-1.43145, -1.43145, -1.107]\n",
      "\tNext action: \"down\" to state 8 with Q-value = -1.107 and reward = -1\n",
      "\tUpdated Q-value: -1.43145\n",
      "Step 158:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"right\" to state 9 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 159:\n",
      "\tCurrent state: 9\n",
      "\tNeighbor states: [('4', 'up'), ('8', 'left'), ('10', 'right'), ('14', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"left\" to state 8 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 160:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.9854999999999999, -0.7649999999999999]\n",
      "\tNext action: \"down\" to state 13 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 161:\n",
      "\tCurrent state: 13\n",
      "\tNeighbor states: [('8', 'up'), ('12', 'left'), ('14', 'right'), ('18', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"right\" to state 14 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 162:\n",
      "\tCurrent state: 14\n",
      "\tNeighbor states: [('9', 'up'), ('13', 'left'), ('15', 'right'), ('19', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"left\" to state 13 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 163:\n",
      "\tCurrent state: 13\n",
      "\tNeighbor states: [('8', 'up'), ('12', 'left'), ('14', 'right'), ('18', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 18 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 164:\n",
      "\tCurrent state: 18\n",
      "\tNeighbor states: [('13', 'up'), ('17', 'left'), ('19', 'right'), ('23', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0, 0]\n",
      "\tNext action: \"right\" to state 19 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 165:\n",
      "\tCurrent state: 19\n",
      "\tNeighbor states: [('14', 'up'), ('18', 'left'), ('20', 'right'), ('24', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0, 0]\n",
      "\tNext action: \"left\" to state 18 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 166:\n",
      "\tCurrent state: 18\n",
      "\tNeighbor states: [('13', 'up'), ('17', 'left'), ('19', 'right'), ('23', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 23 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 167:\n",
      "\tCurrent state: 23\n",
      "\tNeighbor states: [('18', 'up'), ('22', 'left'), ('24', 'right')]\n",
      "\tNeighbor states Q-values: [0, 0, 0]\n",
      "\tNext action: \"up\" to state 18 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 168:\n",
      "\tCurrent state: 18\n",
      "\tNeighbor states: [('13', 'up'), ('17', 'left'), ('19', 'right'), ('23', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"up\" to state 13 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 169:\n",
      "\tCurrent state: 13\n",
      "\tNeighbor states: [('8', 'up'), ('12', 'left'), ('14', 'right'), ('18', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"up\" to state 8 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.107\n",
      "Step 170:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"up\" to state 3 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 171:\n",
      "\tCurrent state: 3\n",
      "\tNeighbor states: [('2', 'left'), ('4', 'right'), ('8', 'down')]\n",
      "\tNeighbor states Q-values: [-1.43145, -1.43145, -1.43145]\n",
      "\tNext action: \"left\" to state 2 with Q-value = -1.43145 and reward = -1\n",
      "\tUpdated Q-value: -1.7180999999999997\n",
      "Step 172:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-1.247895, -1.247895, -1.13985]\n",
      "\tNext action: \"down\" to state 7 with Q-value = -1.13985 and reward = -1\n",
      "\tUpdated Q-value: -1.247895\n",
      "Step 173:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -1.13985, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"right\" to state 8 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 174:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -0.9854999999999999, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"left\" to state 7 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 175:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -1.13985, -1.13985, -0.9854999999999999]\n",
      "\tNext action: \"down\" to state 12 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 176:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"right\" to state 13 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 177:\n",
      "\tCurrent state: 13\n",
      "\tNeighbor states: [('8', 'up'), ('12', 'left'), ('14', 'right'), ('18', 'down')]\n",
      "\tNeighbor states Q-values: [-1.107, -0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"left\" to state 12 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.107\n",
      "Step 178:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.9854999999999999, -0.7649999999999999]\n",
      "\tNext action: \"down\" to state 17 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 179:\n",
      "\tCurrent state: 17\n",
      "\tNeighbor states: [('12', 'up'), ('16', 'left'), ('18', 'right'), ('22', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"right\" to state 18 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 180:\n",
      "\tCurrent state: 18\n",
      "\tNeighbor states: [('13', 'up'), ('17', 'left'), ('19', 'right'), ('23', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"left\" to state 17 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 181:\n",
      "\tCurrent state: 17\n",
      "\tNeighbor states: [('12', 'up'), ('16', 'left'), ('18', 'right'), ('22', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 22 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 182:\n",
      "\tCurrent state: 22\n",
      "\tNeighbor states: [('17', 'up'), ('21', 'left'), ('23', 'right')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"right\" to state 23 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 183:\n",
      "\tCurrent state: 23\n",
      "\tNeighbor states: [('18', 'up'), ('22', 'left'), ('24', 'right')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0]\n",
      "\tNext action: \"left\" to state 22 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 184:\n",
      "\tCurrent state: 22\n",
      "\tNeighbor states: [('17', 'up'), ('21', 'left'), ('23', 'right')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"up\" to state 17 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 185:\n",
      "\tCurrent state: 17\n",
      "\tNeighbor states: [('12', 'up'), ('16', 'left'), ('18', 'right'), ('22', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"up\" to state 12 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 186:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"up\" to state 7 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 187:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -1.13985, -1.13985, -1.13985]\n",
      "\tNext action: \"up\" to state 2 with Q-value = -1.13985 and reward = -1\n",
      "\tUpdated Q-value: -1.247895\n",
      "Step 188:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-1.247895, -1.247895, -1.247895]\n",
      "\tNext action: \"left\" to state 1 with Q-value = -1.247895 and reward = -1\n",
      "\tUpdated Q-value: -1.3235265\n",
      "Step 189:\n",
      "\tCurrent state: 1\n",
      "\tNeighbor states: [('2', 'right'), ('6', 'down')]\n",
      "\tNeighbor states Q-values: [-1.9604294999999998, -1.7180999999999997]\n",
      "\tNext action: \"down\" to state 6 with Q-value = -1.7180999999999997 and reward = -1\n",
      "\tUpdated Q-value: -1.9604294999999998\n",
      "Step 190:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-1.247895, -1.13985, -1.13985]\n",
      "\tNext action: \"right\" to state 7 with Q-value = -1.13985 and reward = -1\n",
      "\tUpdated Q-value: -1.247895\n",
      "Step 191:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-1.247895, -1.13985, -1.13985, -1.13985]\n",
      "\tNext action: \"left\" to state 6 with Q-value = -1.13985 and reward = -1\n",
      "\tUpdated Q-value: -1.247895\n",
      "Step 192:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-1.247895, -1.247895, -1.13985]\n",
      "\tNext action: \"down\" to state 11 with Q-value = -1.13985 and reward = -1\n",
      "\tUpdated Q-value: -1.247895\n",
      "Step 193:\n",
      "\tCurrent state: 11\n",
      "\tNeighbor states: [('6', 'up'), ('12', 'right'), ('16', 'down')]\n",
      "\tNeighbor states Q-values: [-1.43145, -1.107, -1.107]\n",
      "\tNext action: \"right\" to state 12 with Q-value = -1.107 and reward = -1\n",
      "\tUpdated Q-value: -1.43145\n",
      "Step 194:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -0.9854999999999999, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"left\" to state 11 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 195:\n",
      "\tCurrent state: 11\n",
      "\tNeighbor states: [('6', 'up'), ('12', 'right'), ('16', 'down')]\n",
      "\tNeighbor states Q-values: [-1.43145, -1.43145, -1.107]\n",
      "\tNext action: \"down\" to state 16 with Q-value = -1.107 and reward = -1\n",
      "\tUpdated Q-value: -1.43145\n",
      "Step 196:\n",
      "\tCurrent state: 16\n",
      "\tNeighbor states: [('11', 'up'), ('17', 'right'), ('21', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"right\" to state 17 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 197:\n",
      "\tCurrent state: 17\n",
      "\tNeighbor states: [('12', 'up'), ('16', 'left'), ('18', 'right'), ('22', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"left\" to state 16 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 198:\n",
      "\tCurrent state: 16\n",
      "\tNeighbor states: [('11', 'up'), ('17', 'right'), ('21', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.7649999999999999]\n",
      "\tNext action: \"down\" to state 21 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 199:\n",
      "\tCurrent state: 21\n",
      "\tNeighbor states: [('16', 'up'), ('22', 'right')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"right\" to state 22 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.8865\n",
      "Step 200:\n",
      "\tCurrent state: 22\n",
      "\tNeighbor states: [('17', 'up'), ('21', 'left'), ('23', 'right')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"left\" to state 21 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 201:\n",
      "\tCurrent state: 21\n",
      "\tNeighbor states: [('16', 'up'), ('22', 'right')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.8865]\n",
      "\tNext action: \"up\" to state 16 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.107\n",
      "Step 202:\n",
      "\tCurrent state: 16\n",
      "\tNeighbor states: [('11', 'up'), ('17', 'right'), ('21', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"up\" to state 11 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 203:\n",
      "\tCurrent state: 11\n",
      "\tNeighbor states: [('6', 'up'), ('12', 'right'), ('16', 'down')]\n",
      "\tNeighbor states Q-values: [-1.43145, -1.43145, -1.43145]\n",
      "\tNext action: \"up\" to state 6 with Q-value = -1.43145 and reward = -1\n",
      "\tUpdated Q-value: -1.7180999999999997\n",
      "Step 204:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-1.247895, -1.247895, -1.247895]\n",
      "\tNext action: \"up\" to state 1 with Q-value = -1.247895 and reward = -1\n",
      "\tUpdated Q-value: -1.3235265\n",
      "Step 205:\n",
      "\tCurrent state: 1\n",
      "\tNeighbor states: [('2', 'right'), ('6', 'down')]\n",
      "\tNeighbor states Q-values: [-1.9604294999999998, -1.9604294999999998]\n",
      "\tNext action: \"right\" to state 2 with Q-value = -1.9604294999999998 and reward = -1\n",
      "\tUpdated Q-value: -2.1592322999999998\n",
      "Step 206:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-1.3235265, -1.247895, -1.247895]\n",
      "\tNext action: \"right\" to state 3 with Q-value = -1.247895 and reward = -1\n",
      "\tUpdated Q-value: -1.3235265\n",
      "Step 207:\n",
      "\tCurrent state: 3\n",
      "\tNeighbor states: [('2', 'left'), ('4', 'right'), ('8', 'down')]\n",
      "\tNeighbor states Q-values: [-1.7180999999999997, -1.43145, -1.43145]\n",
      "\tNext action: \"right\" to state 4 with Q-value = -1.43145 and reward = -1\n",
      "\tUpdated Q-value: -1.7180999999999997\n",
      "Step 208:\n",
      "\tCurrent state: 4\n",
      "\tNeighbor states: [('3', 'left'), ('5', 'right'), ('9', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"right\" to state 5 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 209:\n",
      "\tCurrent state: 5\n",
      "\tNeighbor states: [('4', 'left'), ('10', 'down')]\n",
      "\tNeighbor states Q-values: [-1.107, -0.7649999999999999]\n",
      "\tNext action: \"down\" to state 10 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.107\n",
      "Step 210:\n",
      "\tCurrent state: 10\n",
      "\tNeighbor states: [('5', 'up'), ('9', 'left'), ('15', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 15 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 211:\n",
      "\tCurrent state: 15\n",
      "\tNeighbor states: [('10', 'up'), ('14', 'left'), ('20', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 20 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 212:\n",
      "\tCurrent state: 20\n",
      "\tNeighbor states: [('15', 'up'), ('19', 'left'), ('25', 'down')]\n",
      "\tNeighbor states Q-values: [0, 0, 0]\n",
      "\tNext action: \"up\" to state 15 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 213:\n",
      "\tCurrent state: 15\n",
      "\tNeighbor states: [('10', 'up'), ('14', 'left'), ('20', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"up\" to state 10 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 214:\n",
      "\tCurrent state: 10\n",
      "\tNeighbor states: [('5', 'up'), ('9', 'left'), ('15', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"up\" to state 5 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 215:\n",
      "\tCurrent state: 5\n",
      "\tNeighbor states: [('4', 'left'), ('10', 'down')]\n",
      "\tNeighbor states Q-values: [-1.107, -1.107]\n",
      "\tNext action: \"left\" to state 4 with Q-value = -1.107 and reward = -1\n",
      "\tUpdated Q-value: -1.43145\n",
      "Step 216:\n",
      "\tCurrent state: 4\n",
      "\tNeighbor states: [('3', 'left'), ('5', 'right'), ('9', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -1.13985, -0.9854999999999999]\n",
      "\tNext action: \"down\" to state 9 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 217:\n",
      "\tCurrent state: 9\n",
      "\tNeighbor states: [('4', 'up'), ('8', 'left'), ('10', 'right'), ('14', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"right\" to state 10 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 218:\n",
      "\tCurrent state: 10\n",
      "\tNeighbor states: [('5', 'up'), ('9', 'left'), ('15', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"left\" to state 9 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 219:\n",
      "\tCurrent state: 9\n",
      "\tNeighbor states: [('4', 'up'), ('8', 'left'), ('10', 'right'), ('14', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.9854999999999999, -0.7649999999999999]\n",
      "\tNext action: \"down\" to state 14 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 220:\n",
      "\tCurrent state: 14\n",
      "\tNeighbor states: [('9', 'up'), ('13', 'left'), ('15', 'right'), ('19', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"right\" to state 15 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 221:\n",
      "\tCurrent state: 15\n",
      "\tNeighbor states: [('10', 'up'), ('14', 'left'), ('20', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"left\" to state 14 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 222:\n",
      "\tCurrent state: 14\n",
      "\tNeighbor states: [('9', 'up'), ('13', 'left'), ('15', 'right'), ('19', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 19 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 223:\n",
      "\tCurrent state: 19\n",
      "\tNeighbor states: [('14', 'up'), ('18', 'left'), ('20', 'right'), ('24', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0, 0]\n",
      "\tNext action: \"right\" to state 20 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 224:\n",
      "\tCurrent state: 20\n",
      "\tNeighbor states: [('15', 'up'), ('19', 'left'), ('25', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0]\n",
      "\tNext action: \"left\" to state 19 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 225:\n",
      "\tCurrent state: 19\n",
      "\tNeighbor states: [('14', 'up'), ('18', 'left'), ('20', 'right'), ('24', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 24 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 226:\n",
      "\tCurrent state: 24\n",
      "\tNeighbor states: [('19', 'up'), ('23', 'left'), ('25', 'right')]\n",
      "\tNeighbor states Q-values: [0, 0, 0]\n",
      "\tNext action: \"up\" to state 19 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 227:\n",
      "\tCurrent state: 19\n",
      "\tNeighbor states: [('14', 'up'), ('18', 'left'), ('20', 'right'), ('24', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"up\" to state 14 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 228:\n",
      "\tCurrent state: 14\n",
      "\tNeighbor states: [('9', 'up'), ('13', 'left'), ('15', 'right'), ('19', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"up\" to state 9 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 229:\n",
      "\tCurrent state: 9\n",
      "\tNeighbor states: [('4', 'up'), ('8', 'left'), ('10', 'right'), ('14', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"up\" to state 4 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 230:\n",
      "\tCurrent state: 4\n",
      "\tNeighbor states: [('3', 'left'), ('5', 'right'), ('9', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -1.13985, -1.13985]\n",
      "\tNext action: \"left\" to state 3 with Q-value = -1.13985 and reward = -1\n",
      "\tUpdated Q-value: -1.247895\n",
      "Step 231:\n",
      "\tCurrent state: 3\n",
      "\tNeighbor states: [('2', 'left'), ('4', 'right'), ('8', 'down')]\n",
      "\tNeighbor states Q-values: [-1.7180999999999997, -1.7180999999999997, -1.43145]\n",
      "\tNext action: \"down\" to state 8 with Q-value = -1.43145 and reward = -1\n",
      "\tUpdated Q-value: -1.7180999999999997\n",
      "Step 232:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -1.13985, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"right\" to state 9 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 233:\n",
      "\tCurrent state: 9\n",
      "\tNeighbor states: [('4', 'up'), ('8', 'left'), ('10', 'right'), ('14', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -0.9854999999999999, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"left\" to state 8 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 234:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -1.13985, -1.13985, -0.9854999999999999]\n",
      "\tNext action: \"down\" to state 13 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 235:\n",
      "\tCurrent state: 13\n",
      "\tNeighbor states: [('8', 'up'), ('12', 'left'), ('14', 'right'), ('18', 'down')]\n",
      "\tNeighbor states Q-values: [-1.107, -1.107, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"right\" to state 14 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.107\n",
      "Step 236:\n",
      "\tCurrent state: 14\n",
      "\tNeighbor states: [('9', 'up'), ('13', 'left'), ('15', 'right'), ('19', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"left\" to state 13 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 237:\n",
      "\tCurrent state: 13\n",
      "\tNeighbor states: [('8', 'up'), ('12', 'left'), ('14', 'right'), ('18', 'down')]\n",
      "\tNeighbor states Q-values: [-1.107, -1.107, -1.107, -0.7649999999999999]\n",
      "\tNext action: \"down\" to state 18 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.107\n",
      "Step 238:\n",
      "\tCurrent state: 18\n",
      "\tNeighbor states: [('13', 'up'), ('17', 'left'), ('19', 'right'), ('23', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"right\" to state 19 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 239:\n",
      "\tCurrent state: 19\n",
      "\tNeighbor states: [('14', 'up'), ('18', 'left'), ('20', 'right'), ('24', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"left\" to state 18 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 240:\n",
      "\tCurrent state: 18\n",
      "\tNeighbor states: [('13', 'up'), ('17', 'left'), ('19', 'right'), ('23', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 23 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 241:\n",
      "\tCurrent state: 23\n",
      "\tNeighbor states: [('18', 'up'), ('22', 'left'), ('24', 'right')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"right\" to state 24 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 242:\n",
      "\tCurrent state: 24\n",
      "\tNeighbor states: [('19', 'up'), ('23', 'left'), ('25', 'right')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, 0, 0]\n",
      "\tNext action: \"left\" to state 23 with Q-value = 0 and reward = -1\n",
      "\tUpdated Q-value: -0.44999999999999996\n",
      "Step 243:\n",
      "\tCurrent state: 23\n",
      "\tNeighbor states: [('18', 'up'), ('22', 'left'), ('24', 'right')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"up\" to state 18 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 244:\n",
      "\tCurrent state: 18\n",
      "\tNeighbor states: [('13', 'up'), ('17', 'left'), ('19', 'right'), ('23', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"up\" to state 13 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 245:\n",
      "\tCurrent state: 13\n",
      "\tNeighbor states: [('8', 'up'), ('12', 'left'), ('14', 'right'), ('18', 'down')]\n",
      "\tNeighbor states Q-values: [-1.107, -1.107, -1.107, -1.107]\n",
      "\tNext action: \"up\" to state 8 with Q-value = -1.107 and reward = -1\n",
      "\tUpdated Q-value: -1.43145\n",
      "Step 246:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -1.13985, -1.13985, -1.13985]\n",
      "\tNext action: \"up\" to state 3 with Q-value = -1.13985 and reward = -1\n",
      "\tUpdated Q-value: -1.247895\n",
      "Step 247:\n",
      "\tCurrent state: 3\n",
      "\tNeighbor states: [('2', 'left'), ('4', 'right'), ('8', 'down')]\n",
      "\tNeighbor states Q-values: [-1.7180999999999997, -1.7180999999999997, -1.7180999999999997]\n",
      "\tNext action: \"left\" to state 2 with Q-value = -1.7180999999999997 and reward = -1\n",
      "\tUpdated Q-value: -1.9604294999999998\n",
      "Step 248:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-1.3235265, -1.3235265, -1.247895]\n",
      "\tNext action: \"down\" to state 7 with Q-value = -1.247895 and reward = -1\n",
      "\tUpdated Q-value: -1.3235265\n",
      "Step 249:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-1.247895, -1.247895, -1.13985, -1.13985]\n",
      "\tNext action: \"right\" to state 8 with Q-value = -1.13985 and reward = -1\n",
      "\tUpdated Q-value: -1.247895\n",
      "Step 250:\n",
      "\tCurrent state: 8\n",
      "\tNeighbor states: [('3', 'up'), ('7', 'left'), ('9', 'right'), ('13', 'down')]\n",
      "\tNeighbor states Q-values: [-1.247895, -1.13985, -1.13985, -1.13985]\n",
      "\tNext action: \"left\" to state 7 with Q-value = -1.13985 and reward = -1\n",
      "\tUpdated Q-value: -1.247895\n",
      "Step 251:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-1.247895, -1.247895, -1.247895, -1.13985]\n",
      "\tNext action: \"down\" to state 12 with Q-value = -1.13985 and reward = -1\n",
      "\tUpdated Q-value: -1.247895\n",
      "Step 252:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -1.13985, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"right\" to state 13 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 253:\n",
      "\tCurrent state: 13\n",
      "\tNeighbor states: [('8', 'up'), ('12', 'left'), ('14', 'right'), ('18', 'down')]\n",
      "\tNeighbor states Q-values: [-1.43145, -1.107, -1.107, -1.107]\n",
      "\tNext action: \"left\" to state 12 with Q-value = -1.107 and reward = -1\n",
      "\tUpdated Q-value: -1.43145\n",
      "Step 254:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -1.13985, -1.13985, -0.9854999999999999]\n",
      "\tNext action: \"down\" to state 17 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 255:\n",
      "\tCurrent state: 17\n",
      "\tNeighbor states: [('12', 'up'), ('16', 'left'), ('18', 'right'), ('22', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"right\" to state 18 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 256:\n",
      "\tCurrent state: 18\n",
      "\tNeighbor states: [('13', 'up'), ('17', 'left'), ('19', 'right'), ('23', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"left\" to state 17 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 257:\n",
      "\tCurrent state: 17\n",
      "\tNeighbor states: [('12', 'up'), ('16', 'left'), ('18', 'right'), ('22', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.9854999999999999, -0.7649999999999999]\n",
      "\tNext action: \"down\" to state 22 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 258:\n",
      "\tCurrent state: 22\n",
      "\tNeighbor states: [('17', 'up'), ('21', 'left'), ('23', 'right')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"right\" to state 23 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 259:\n",
      "\tCurrent state: 23\n",
      "\tNeighbor states: [('18', 'up'), ('22', 'left'), ('24', 'right')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.44999999999999996, -0.44999999999999996]\n",
      "\tNext action: \"left\" to state 22 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 260:\n",
      "\tCurrent state: 22\n",
      "\tNeighbor states: [('17', 'up'), ('21', 'left'), ('23', 'right')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"up\" to state 17 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 261:\n",
      "\tCurrent state: 17\n",
      "\tNeighbor states: [('12', 'up'), ('16', 'left'), ('18', 'right'), ('22', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"up\" to state 12 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 262:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -1.13985, -1.13985, -1.13985]\n",
      "\tNext action: \"up\" to state 7 with Q-value = -1.13985 and reward = -1\n",
      "\tUpdated Q-value: -1.247895\n",
      "Step 263:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-1.247895, -1.247895, -1.247895, -1.247895]\n",
      "\tNext action: \"up\" to state 2 with Q-value = -1.247895 and reward = -1\n",
      "\tUpdated Q-value: -1.3235265\n",
      "Step 264:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-1.3235265, -1.3235265, -1.3235265]\n",
      "\tNext action: \"left\" to state 1 with Q-value = -1.3235265 and reward = -1\n",
      "\tUpdated Q-value: -1.37646855\n",
      "Step 265:\n",
      "\tCurrent state: 1\n",
      "\tNeighbor states: [('2', 'right'), ('6', 'down')]\n",
      "\tNeighbor states Q-values: [-2.1592322999999998, -1.9604294999999998]\n",
      "\tNext action: \"down\" to state 6 with Q-value = -1.9604294999999998 and reward = -1\n",
      "\tUpdated Q-value: -2.1592322999999998\n",
      "Step 266:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-1.3235265, -1.247895, -1.247895]\n",
      "\tNext action: \"right\" to state 7 with Q-value = -1.247895 and reward = -1\n",
      "\tUpdated Q-value: -1.3235265\n",
      "Step 267:\n",
      "\tCurrent state: 7\n",
      "\tNeighbor states: [('2', 'up'), ('6', 'left'), ('8', 'right'), ('12', 'down')]\n",
      "\tNeighbor states Q-values: [-1.3235265, -1.247895, -1.247895, -1.247895]\n",
      "\tNext action: \"left\" to state 6 with Q-value = -1.247895 and reward = -1\n",
      "\tUpdated Q-value: -1.3235265\n",
      "Step 268:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-1.3235265, -1.3235265, -1.247895]\n",
      "\tNext action: \"down\" to state 11 with Q-value = -1.247895 and reward = -1\n",
      "\tUpdated Q-value: -1.3235265\n",
      "Step 269:\n",
      "\tCurrent state: 11\n",
      "\tNeighbor states: [('6', 'up'), ('12', 'right'), ('16', 'down')]\n",
      "\tNeighbor states Q-values: [-1.7180999999999997, -1.43145, -1.43145]\n",
      "\tNext action: \"right\" to state 12 with Q-value = -1.43145 and reward = -1\n",
      "\tUpdated Q-value: -1.7180999999999997\n",
      "Step 270:\n",
      "\tCurrent state: 12\n",
      "\tNeighbor states: [('7', 'up'), ('11', 'left'), ('13', 'right'), ('17', 'down')]\n",
      "\tNeighbor states Q-values: [-1.247895, -1.13985, -1.13985, -1.13985]\n",
      "\tNext action: \"left\" to state 11 with Q-value = -1.13985 and reward = -1\n",
      "\tUpdated Q-value: -1.247895\n",
      "Step 271:\n",
      "\tCurrent state: 11\n",
      "\tNeighbor states: [('6', 'up'), ('12', 'right'), ('16', 'down')]\n",
      "\tNeighbor states Q-values: [-1.7180999999999997, -1.7180999999999997, -1.43145]\n",
      "\tNext action: \"down\" to state 16 with Q-value = -1.43145 and reward = -1\n",
      "\tUpdated Q-value: -1.7180999999999997\n",
      "Step 272:\n",
      "\tCurrent state: 16\n",
      "\tNeighbor states: [('11', 'up'), ('17', 'right'), ('21', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"right\" to state 17 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 273:\n",
      "\tCurrent state: 17\n",
      "\tNeighbor states: [('12', 'up'), ('16', 'left'), ('18', 'right'), ('22', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -0.9854999999999999, -0.9854999999999999, -0.9854999999999999]\n",
      "\tNext action: \"left\" to state 16 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 274:\n",
      "\tCurrent state: 16\n",
      "\tNeighbor states: [('11', 'up'), ('17', 'right'), ('21', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -1.13985, -0.9854999999999999]\n",
      "\tNext action: \"down\" to state 21 with Q-value = -0.9854999999999999 and reward = -1\n",
      "\tUpdated Q-value: -1.13985\n",
      "Step 275:\n",
      "\tCurrent state: 21\n",
      "\tNeighbor states: [('16', 'up'), ('22', 'right')]\n",
      "\tNeighbor states Q-values: [-1.107, -0.8865]\n",
      "\tNext action: \"right\" to state 22 with Q-value = -0.8865 and reward = -1\n",
      "\tUpdated Q-value: -1.2771\n",
      "Step 276:\n",
      "\tCurrent state: 22\n",
      "\tNeighbor states: [('17', 'up'), ('21', 'left'), ('23', 'right')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.7649999999999999, -0.7649999999999999]\n",
      "\tNext action: \"left\" to state 21 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 277:\n",
      "\tCurrent state: 21\n",
      "\tNeighbor states: [('16', 'up'), ('22', 'right')]\n",
      "\tNeighbor states Q-values: [-1.107, -1.2771]\n",
      "\tNext action: \"up\" to state 16 with Q-value = -1.107 and reward = -1\n",
      "\tUpdated Q-value: -1.43145\n",
      "Step 278:\n",
      "\tCurrent state: 16\n",
      "\tNeighbor states: [('11', 'up'), ('17', 'right'), ('21', 'down')]\n",
      "\tNeighbor states Q-values: [-1.13985, -1.13985, -1.13985]\n",
      "\tNext action: \"up\" to state 11 with Q-value = -1.13985 and reward = -1\n",
      "\tUpdated Q-value: -1.247895\n",
      "Step 279:\n",
      "\tCurrent state: 11\n",
      "\tNeighbor states: [('6', 'up'), ('12', 'right'), ('16', 'down')]\n",
      "\tNeighbor states Q-values: [-1.7180999999999997, -1.7180999999999997, -1.7180999999999997]\n",
      "\tNext action: \"up\" to state 6 with Q-value = -1.7180999999999997 and reward = -1\n",
      "\tUpdated Q-value: -1.9604294999999998\n",
      "Step 280:\n",
      "\tCurrent state: 6\n",
      "\tNeighbor states: [('1', 'up'), ('7', 'right'), ('11', 'down')]\n",
      "\tNeighbor states Q-values: [-1.3235265, -1.3235265, -1.3235265]\n",
      "\tNext action: \"up\" to state 1 with Q-value = -1.3235265 and reward = -1\n",
      "\tUpdated Q-value: -1.37646855\n",
      "Step 281:\n",
      "\tCurrent state: 1\n",
      "\tNeighbor states: [('2', 'right'), ('6', 'down')]\n",
      "\tNeighbor states Q-values: [-2.1592322999999998, -2.1592322999999998]\n",
      "\tNext action: \"right\" to state 2 with Q-value = -2.1592322999999998 and reward = -1\n",
      "\tUpdated Q-value: -2.318814765\n",
      "Step 282:\n",
      "\tCurrent state: 2\n",
      "\tNeighbor states: [('1', 'left'), ('3', 'right'), ('7', 'down')]\n",
      "\tNeighbor states Q-values: [-1.37646855, -1.3235265, -1.3235265]\n",
      "\tNext action: \"right\" to state 3 with Q-value = -1.3235265 and reward = -1\n",
      "\tUpdated Q-value: -1.37646855\n",
      "Step 283:\n",
      "\tCurrent state: 3\n",
      "\tNeighbor states: [('2', 'left'), ('4', 'right'), ('8', 'down')]\n",
      "\tNeighbor states Q-values: [-1.9604294999999998, -1.7180999999999997, -1.7180999999999997]\n",
      "\tNext action: \"right\" to state 4 with Q-value = -1.7180999999999997 and reward = -1\n",
      "\tUpdated Q-value: -1.9604294999999998\n",
      "Step 284:\n",
      "\tCurrent state: 4\n",
      "\tNeighbor states: [('3', 'left'), ('5', 'right'), ('9', 'down')]\n",
      "\tNeighbor states Q-values: [-1.247895, -1.13985, -1.13985]\n",
      "\tNext action: \"right\" to state 5 with Q-value = -1.13985 and reward = -1\n",
      "\tUpdated Q-value: -1.247895\n",
      "Step 285:\n",
      "\tCurrent state: 5\n",
      "\tNeighbor states: [('4', 'left'), ('10', 'down')]\n",
      "\tNeighbor states Q-values: [-1.43145, -1.107]\n",
      "\tNext action: \"down\" to state 10 with Q-value = -1.107 and reward = -1\n",
      "\tUpdated Q-value: -1.43145\n",
      "Step 286:\n",
      "\tCurrent state: 10\n",
      "\tNeighbor states: [('5', 'up'), ('9', 'left'), ('15', 'down')]\n",
      "\tNeighbor states Q-values: [-0.9854999999999999, -0.9854999999999999, -0.7649999999999999]\n",
      "\tNext action: \"down\" to state 15 with Q-value = -0.7649999999999999 and reward = -1\n",
      "\tUpdated Q-value: -0.9854999999999999\n",
      "Step 287:\n",
      "\tCurrent state: 15\n",
      "\tNeighbor states: [('10', 'up'), ('14', 'left'), ('20', 'down')]\n",
      "\tNeighbor states Q-values: [-0.7649999999999999, -0.7649999999999999, -0.44999999999999996]\n",
      "\tNext action: \"down\" to state 20 with Q-value = -0.44999999999999996 and reward = -1\n",
      "\tUpdated Q-value: -0.7649999999999999\n",
      "Step 288:\n",
      "\tCurrent state: 20\n",
      "\tNeighbor states: [('15', 'up'), ('19', 'left'), ('25', 'down')]\n",
      "\tNeighbor states Q-values: [-0.44999999999999996, -0.44999999999999996, 0]\n",
      "\tNext action: \"down\" to state 25 with Q-value = 0 and reward = 10\n",
      "\tUpdated Q-value: 2.85\n",
      "Step 289:\n",
      "\tCurrent state: 25\n",
      "Goal state found at iteration 289\n"
     ]
    }
   ],
   "source": [
    "# Main Q-Learning Loop\n",
    "\n",
    "current_state = \"1\"  # Initialize the starting state\n",
    "states_follow_up = [current_state]  # Track the sequence of states visited\n",
    "\n",
    "# Maximum number of iterations to prevent infinite loops\n",
    "max_iterations = 1_000_000\n",
    "\n",
    "for i in range(max_iterations):\n",
    "    print(f\"Step {i + 1}:\")\n",
    "    print(f\"\\tCurrent state: {current_state}\")\n",
    "\n",
    "    # Check if the goal state is reached\n",
    "    if current_state == \"25\":\n",
    "        print(f\"Goal state found at iteration {i + 1}\")\n",
    "        break\n",
    "\n",
    "    # Retrieve neighboring states and their Q-values\n",
    "    neighbor_states = get_neighbor_states(state=current_state)\n",
    "    neighbor_states_Q = get_neighbor_states_Q(current_state=current_state, neighbor_states=neighbor_states)\n",
    "    print(f\"\\tNeighbor states: {neighbor_states}\")\n",
    "    print(f\"\\tNeighbor states Q-values: {neighbor_states_Q}\")\n",
    "\n",
    "    # Select the next state based on the highest Q-value\n",
    "    next_state = get_next_state(current_state=current_state, neighbor_states=neighbor_states)\n",
    "    next_state_Q = get_state_Q(state=current_state, action=next_state[1])\n",
    "    next_state_reward = get_reward(next_state[0])\n",
    "    print(f'\\tNext action: \"{next_state[1]}\" to state {next_state[0]} with Q-value = {next_state_Q} and reward = {next_state_reward}')\n",
    "\n",
    "    # Update the Q-value for the current state-action pair\n",
    "    updated_Q = get_Q_update(\n",
    "        state_Q=next_state_Q,\n",
    "        state_reward=next_state_reward,\n",
    "        neighbor_states=neighbor_states,\n",
    "        learning_rate=0.3,\n",
    "        discount_factor=0.9,\n",
    "        step_penalty=-0.5\n",
    "    )\n",
    "    set_state_Q(state=current_state, action=next_state[1], new_value=updated_Q)\n",
    "    print(f\"\\tUpdated Q-value: {get_state_Q(state=current_state, action=next_state[1])}\")\n",
    "\n",
    "    # Transition to the next state\n",
    "    current_state = next_state[0]\n",
    "    states_follow_up.append(current_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
