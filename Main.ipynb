{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **1**  | **2**  | **3**  | **4**  |\n",
    "| ------ | ------ | ------ | ------ |\n",
    "| **5**  | **6**  | **7**  | **8**  |\n",
    "| **9**  | **10** | **11** | **12** |\n",
    "| **13** | **14** | **15** | **16** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Q(s_t, a_t) \\leftarrow Q(s_t, a_t) + \\alpha  (R_t + \\gamma \\max_{a} Q(s_{t+1,},a) - Q(s_t, a_t))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_graph = {\n",
    "    \"1\": [(\"2\", \"right\"), (\"5\", \"down\")],\n",
    "    \"2\": [(\"1\", \"left\"), (\"3\", \"right\"), (\"6\", \"down\")],\n",
    "    \"3\": [(\"2\", \"left\"), (\"4\", \"right\"), (\"7\", \"down\")],\n",
    "    \"4\": [(\"3\", \"left\"), (\"8\", \"down\")],\n",
    "    \"5\": [(\"1\", \"up\"), (\"6\", \"right\"), (\"9\", \"down\")],\n",
    "    \"6\": [(\"2\", \"up\"), (\"5\", \"left\"), (\"7\", \"right\"), (\"10\", \"down\")],\n",
    "    \"7\": [(\"3\", \"up\"), (\"6\", \"left\"), (\"8\", \"right\"), (\"11\", \"down\")],\n",
    "    \"8\": [(\"4\", \"up\"), (\"7\", \"left\"), (\"12\", \"down\")],\n",
    "    \"9\": [(\"5\", \"up\"), (\"10\", \"right\"), (\"13\", \"down\")],\n",
    "    \"10\": [(\"6\", \"up\"), (\"9\", \"left\"), (\"11\", \"right\"), (\"14\", \"down\")],\n",
    "    \"11\": [(\"7\", \"up\"), (\"10\", \"left\"), (\"12\", \"right\"), (\"15\", \"down\")],\n",
    "    \"12\": [(\"8\", \"up\"), (\"11\", \"left\"), (\"16\", \"down\")],\n",
    "    \"13\": [(\"9\", \"up\"), (\"14\", \"right\")],\n",
    "    \"14\": [(\"10\", \"up\"), (\"13\", \"left\"), (\"15\", \"right\")],\n",
    "    \"15\": [(\"11\", \"up\"), (\"14\", \"left\"), (\"16\", \"right\")],\n",
    "    \"16\": [(\"12\", \"up\"), (\"15\", \"left\")],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_states = {\n",
    "    \"1\": {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0},\n",
    "    \"2\": {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0},\n",
    "    \"3\": {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0},\n",
    "    \"4\": {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0},\n",
    "    \"5\": {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0},\n",
    "    \"6\": {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0},\n",
    "    \"7\": {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0},\n",
    "    \"8\": {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0},\n",
    "    \"9\": {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0},\n",
    "    \"10\": {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0},\n",
    "    \"11\": {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0},\n",
    "    \"12\": {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0},\n",
    "    \"13\": {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0},\n",
    "    \"14\": {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0},\n",
    "    \"15\": {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0},\n",
    "    \"16\": {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0},\n",
    "}\n",
    "\n",
    "\n",
    "rewards = {\n",
    "    \"1\": -1,\n",
    "    \"2\": -1,\n",
    "    \"3\": -1,\n",
    "    \"4\": -1,\n",
    "    \"5\": -1,\n",
    "    \"6\": -1,\n",
    "    \"7\": -1,\n",
    "    \"8\": -1,\n",
    "    \"9\": -1,\n",
    "    \"10\": -1,\n",
    "    \"11\": -1,\n",
    "    \"12\": -1,\n",
    "    \"13\": -1,\n",
    "    \"14\": -1,\n",
    "    \"15\": -1,\n",
    "    \"16\": 10,\n",
    "}\n",
    "\n",
    "\n",
    "def get_neighbor_states(state: str) -> list[tuple[str, str]]:\n",
    "    return grid_graph[state]\n",
    "\n",
    "\n",
    "def get_state_Q(state: str, action: str) -> int:\n",
    "\n",
    "    return Q_states[state][action]\n",
    "\n",
    "\n",
    "def set_state_Q(state: str, action: str, new_value: float) -> int:\n",
    "    Q_states[state][action] = new_value\n",
    "\n",
    "\n",
    "def get_reward(state: str) -> int:\n",
    "\n",
    "    return rewards[state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Q_update(\n",
    "    state_Q: float,\n",
    "    state_reward: float,\n",
    "    neighbor_states: list[str],\n",
    "    learning_rate: float = 0.5,\n",
    "    discount_factor: float = 0.5,\n",
    ") -> float:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        state_Q (float): Q value of a state\n",
    "        state_reward (float): reward of a state\n",
    "        learning_rate (float, optional): how much to update the Q-value. Defaults to .5.\n",
    "        discount_factor (float, optional): how much future rewards are taken into account. Defaults to .5.\n",
    "\n",
    "    Returns:\n",
    "        float: _description_\n",
    "    \"\"\"\n",
    "    neighbor_states_Q = map(lambda x: get_state_Q(*x), neighbor_states)\n",
    "    return state_Q + learning_rate * (\n",
    "        state_reward + discount_factor * max(neighbor_states_Q) - state_Q\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbor_states_Q(current_state, neighbor_states):\n",
    "    return list(map(lambda x: get_state_Q(*x), [[current_state, j] for _,j in neighbor_states]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_state(current_state, neighbor_states):\n",
    "    neighbor_states_Q = get_neighbor_states_Q(current_state, neighbor_states)\n",
    "    return neighbor_states[np.argmax(neighbor_states_Q)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "\tcurrent state: 1\n",
      "\tneighbor states: [('2', 'right'), ('5', 'down')] \n",
      "\tneighbor states: [0, 0] \n",
      "\tNext action: \"right\" to state 2 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -0.5\n",
      "Step 2:\n",
      "\tcurrent state: 2\n",
      "\tneighbor states: [('1', 'left'), ('3', 'right'), ('6', 'down')] \n",
      "\tneighbor states: [0, 0, 0] \n",
      "\tNext action: \"left\" to state 1 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -0.5\n",
      "Step 3:\n",
      "\tcurrent state: 1\n",
      "\tneighbor states: [('2', 'right'), ('5', 'down')] \n",
      "\tneighbor states: [-0.5, 0] \n",
      "\tNext action: \"down\" to state 5 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -0.5\n",
      "Step 4:\n",
      "\tcurrent state: 5\n",
      "\tneighbor states: [('1', 'up'), ('6', 'right'), ('9', 'down')] \n",
      "\tneighbor states: [0, 0, 0] \n",
      "\tNext action: \"up\" to state 1 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -0.5\n"
     ]
    }
   ],
   "source": [
    "current_state = \"1\"\n",
    "\n",
    "states_follow_up = []\n",
    "for i in range(4):\n",
    "    print(f\"Step {i+1}:\")\n",
    "    print(f\"\\tcurrent state: {current_state}\")\n",
    "\n",
    "    neighbor_states = get_neighbor_states(state=current_state)\n",
    "    neighbor_states_Q = get_neighbor_states_Q(current_state=current_state,neighbor_states=neighbor_states)\n",
    "    print(\n",
    "        f\"\\tneighbor states: {neighbor_states} \"\n",
    "    )\n",
    "    print(\n",
    "        f\"\\tneighbor states: {neighbor_states_Q} \"\n",
    "    )\n",
    "    \n",
    "\n",
    "    next_state = get_next_state(\n",
    "        current_state=current_state, neighbor_states=neighbor_states\n",
    "    )\n",
    "    next_state_Q = get_state_Q(*next_state)\n",
    "    next_state_reward = get_reward(next_state[0])\n",
    "    print(\n",
    "        f'\\tNext action: \"{next_state[1]}\" to state {next_state[0]} with Q value = {next_state_Q} and reward = {next_state_reward}'\n",
    "    )\n",
    "\n",
    "    updated_Q = get_Q_update(\n",
    "        state_Q=next_state_Q,\n",
    "        state_reward=next_state_reward,\n",
    "        neighbor_states=neighbor_states,\n",
    "    )\n",
    "    set_state_Q(state=current_state, action=next_state[1], new_value=updated_Q)\n",
    "    print(\n",
    "        f\"\\tUpdates Q value: {get_state_Q(state=current_state, action=next_state[1])}\"\n",
    "    )\n",
    "\n",
    "    current_state = next_state[0]\n",
    "    states_follow_up.append(current_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'right': -0.5, 'up': 0, 'left': 0, 'down': -0.5},\n",
       " '2': {'right': 0, 'up': 0, 'left': -0.5, 'down': 0},\n",
       " '3': {'right': 0, 'up': 0, 'left': 0, 'down': 0},\n",
       " '4': {'right': 0, 'up': 0, 'left': 0, 'down': 0},\n",
       " '5': {'right': 0, 'up': -0.5, 'left': 0, 'down': 0},\n",
       " '6': {'right': 0, 'up': 0, 'left': 0, 'down': 0},\n",
       " '7': {'right': 0, 'up': 0, 'left': 0, 'down': 0},\n",
       " '8': {'right': 0, 'up': 0, 'left': 0, 'down': 0},\n",
       " '9': {'right': 0, 'up': 0, 'left': 0, 'down': 0},\n",
       " '10': {'right': 0, 'up': 0, 'left': 0, 'down': 0},\n",
       " '11': {'right': 0, 'up': 0, 'left': 0, 'down': 0},\n",
       " '12': {'right': 0, 'up': 0, 'left': 0, 'down': 0},\n",
       " '13': {'right': 0, 'up': 0, 'left': 0, 'down': 0},\n",
       " '14': {'right': 0, 'up': 0, 'left': 0, 'down': 0},\n",
       " '15': {'right': 0, 'up': 0, 'left': 0, 'down': 0},\n",
       " '16': {'right': 0, 'up': 0, 'left': 0, 'down': 0}}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_states"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
