{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Q(s_t, a_t) \\leftarrow Q(s_t, a_t) + \\alpha  (R_t + \\gamma \\max_{a} Q(s_{t+1,},a) - Q(s_t, a_t))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid 4x4\n",
    "grid_graph = {\n",
    "    \"1\": [(\"2\", \"right\"), (\"5\", \"down\")],\n",
    "    \"2\": [(\"1\", \"left\"), (\"3\", \"right\"), (\"6\", \"down\")],\n",
    "    \"3\": [(\"2\", \"left\"), (\"4\", \"right\"), (\"7\", \"down\")],\n",
    "    \"4\": [(\"3\", \"left\"), (\"8\", \"down\")],\n",
    "    \"5\": [(\"1\", \"up\"), (\"6\", \"right\"), (\"9\", \"down\")],\n",
    "    \"6\": [(\"2\", \"up\"), (\"5\", \"left\"), (\"7\", \"right\"), (\"10\", \"down\")],\n",
    "    \"7\": [(\"3\", \"up\"), (\"6\", \"left\"), (\"8\", \"right\"), (\"11\", \"down\")],\n",
    "    \"8\": [(\"4\", \"up\"), (\"7\", \"left\"), (\"12\", \"down\")],\n",
    "    \"9\": [(\"5\", \"up\"), (\"10\", \"right\"), (\"13\", \"down\")],\n",
    "    \"10\": [(\"6\", \"up\"), (\"9\", \"left\"), (\"11\", \"right\"), (\"14\", \"down\")],\n",
    "    \"11\": [(\"7\", \"up\"), (\"10\", \"left\"), (\"12\", \"right\"), (\"15\", \"down\")],\n",
    "    \"12\": [(\"8\", \"up\"), (\"11\", \"left\"), (\"16\", \"down\")],\n",
    "    \"13\": [(\"9\", \"up\"), (\"14\", \"right\")],\n",
    "    \"14\": [(\"10\", \"up\"), (\"13\", \"left\"), (\"15\", \"right\")],\n",
    "    \"15\": [(\"11\", \"up\"), (\"14\", \"left\"), (\"16\", \"right\")],\n",
    "    \"16\": [(\"12\", \"up\"), (\"15\", \"left\")],\n",
    "}\n",
    "\n",
    "# Grid 3x3\n",
    "# grid_graph = {\n",
    "#     \"1\": [(\"2\", \"right\"), (\"4\", \"down\")],\n",
    "#     \"2\": [(\"1\", \"left\"), (\"3\", \"right\"), (\"5\", \"down\")],\n",
    "#     \"3\": [(\"2\", \"left\"), (\"6\", \"down\")],\n",
    "\n",
    "#     \"4\": [(\"1\", \"up\"), (\"5\", \"right\"), (\"7\", \"down\")],\n",
    "#     \"5\": [(\"2\", \"up\"), (\"4\", \"left\"), (\"6\", \"right\"), (\"8\", \"down\")],\n",
    "#     \"6\": [(\"3\", \"up\"), (\"5\", \"left\"), (\"9\", \"down\")],\n",
    "\n",
    "#     \"7\": [(\"4\", \"up\"), (\"8\", \"right\")],\n",
    "#     \"8\": [(\"5\", \"up\"), (\"7\", \"left\"), (\"9\", \"right\")],\n",
    "#     \"9\": [(\"6\", \"up\"), (\"8\", \"left\")]\n",
    "# }\n",
    "\n",
    "# Grid 5x5\n",
    "# grid_graph = {\n",
    "#     \"1\": [(\"2\", \"right\"), (\"6\", \"down\")],\n",
    "#     \"2\": [(\"1\", \"left\"), (\"3\", \"right\"), (\"7\", \"down\")],\n",
    "#     \"3\": [(\"2\", \"left\"), (\"4\", \"right\"), (\"8\", \"down\")],\n",
    "#     \"4\": [(\"3\", \"left\"), (\"5\", \"right\"), (\"9\", \"down\")],\n",
    "#     \"5\": [(\"4\", \"left\"), (\"10\", \"down\")],\n",
    "\n",
    "#     \"6\": [(\"1\", \"up\"), (\"7\", \"right\"), (\"11\", \"down\")],\n",
    "#     \"7\": [(\"2\", \"up\"), (\"6\", \"left\"), (\"8\", \"right\"), (\"12\", \"down\")],\n",
    "#     \"8\": [(\"3\", \"up\"), (\"7\", \"left\"), (\"9\", \"right\"), (\"13\", \"down\")],\n",
    "#     \"9\": [(\"4\", \"up\"), (\"8\", \"left\"), (\"10\", \"right\"), (\"14\", \"down\")],\n",
    "#     \"10\": [(\"5\", \"up\"), (\"9\", \"left\"), (\"15\", \"down\")],\n",
    "\n",
    "#     \"11\": [(\"6\", \"up\"), (\"12\", \"right\"), (\"16\", \"down\")],\n",
    "#     \"12\": [(\"7\", \"up\"), (\"11\", \"left\"), (\"13\", \"right\"), (\"17\", \"down\")],\n",
    "#     \"13\": [(\"8\", \"up\"), (\"12\", \"left\"), (\"14\", \"right\"), (\"18\", \"down\")],\n",
    "#     \"14\": [(\"9\", \"up\"), (\"13\", \"left\"), (\"15\", \"right\"), (\"19\", \"down\")],\n",
    "#     \"15\": [(\"10\", \"up\"), (\"14\", \"left\"), (\"20\", \"down\")],\n",
    "\n",
    "#     \"16\": [(\"11\", \"up\"), (\"17\", \"right\"), (\"21\", \"down\")],\n",
    "#     \"17\": [(\"12\", \"up\"), (\"16\", \"left\"), (\"18\", \"right\"), (\"22\", \"down\")],\n",
    "#     \"18\": [(\"13\", \"up\"), (\"17\", \"left\"), (\"19\", \"right\"), (\"23\", \"down\")],\n",
    "#     \"19\": [(\"14\", \"up\"), (\"18\", \"left\"), (\"20\", \"right\"), (\"24\", \"down\")],\n",
    "#     \"20\": [(\"15\", \"up\"), (\"19\", \"left\"), (\"25\", \"down\")],\n",
    "\n",
    "#     \"21\": [(\"16\", \"up\"), (\"22\", \"right\")],\n",
    "#     \"22\": [(\"17\", \"up\"), (\"21\", \"left\"), (\"23\", \"right\")],\n",
    "#     \"23\": [(\"18\", \"up\"), (\"22\", \"left\"), (\"24\", \"right\")],\n",
    "#     \"24\": [(\"19\", \"up\"), (\"23\", \"left\"), (\"25\", \"right\")],\n",
    "#     \"25\": [(\"20\", \"up\"), (\"24\", \"left\")]\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_states = {str(i): {\"right\": 0, \"up\": 0, \"left\": 0, \"down\": 0} for i in range(1, 26)}\n",
    "\n",
    "\n",
    "rewards = {str(i): -1 for i in range(1, len(grid_graph) + 1)}\n",
    "rewards[0] = -10\n",
    "rewards[-1] = 10\n",
    "\n",
    "\n",
    "def get_neighbor_states(state: str) -> list[tuple[str, str]]:\n",
    "    return grid_graph[state]\n",
    "\n",
    "\n",
    "def get_state_Q(state: str, action: str) -> int:\n",
    "\n",
    "    return Q_states[state][action]\n",
    "\n",
    "\n",
    "def set_state_Q(state: str, action: str, new_value: float) -> int:\n",
    "    Q_states[state][action] = new_value\n",
    "\n",
    "\n",
    "def get_reward(state: str) -> int:\n",
    "\n",
    "    return rewards[state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Q_update(\n",
    "    state_Q: float,\n",
    "    state_reward: float,\n",
    "    neighbor_states: list[str],\n",
    "    learning_rate: float = 0.5,\n",
    "    discount_factor: float = 0.5,\n",
    "    step_penalty:float = 0\n",
    ") -> float:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        state_Q (float): Q value of a state\n",
    "        state_reward (float): reward of a state\n",
    "        learning_rate (float, optional): how much to update the Q-value. Defaults to .5.\n",
    "        discount_factor (float, optional): how much future rewards are taken into account. Defaults to .5.\n",
    "\n",
    "    Returns:\n",
    "        float: _description_\n",
    "    \"\"\"\n",
    "    neighbor_states_Q = map(lambda x: get_state_Q(*x), neighbor_states)\n",
    "    return state_Q + learning_rate * (\n",
    "        (state_reward + step_penalty) + discount_factor * max(neighbor_states_Q) - state_Q\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbor_states_Q(current_state, neighbor_states):\n",
    "    return list(\n",
    "        map(lambda x: get_state_Q(*x), [[current_state, j] for _, j in neighbor_states])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_state(current_state, neighbor_states):\n",
    "    neighbor_states_Q = get_neighbor_states_Q(current_state, neighbor_states)\n",
    "    return neighbor_states[np.argmax(neighbor_states_Q)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(current_state, neighbor_states, epsilon=0):\n",
    "    # neighbor_states = get_neighbor_states(state)\n",
    "    if np.random.random() < epsilon:\n",
    "        np.random.shuffle(neighbor_states)\n",
    "        return  neighbor_states[0]\n",
    "    return get_next_state(current_state, neighbor_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "\tcurrent state: 1\n",
      "\tneighbor states: [('2', 'right'), ('5', 'down')] \n",
      "\tneighbor states Q values: [0, 0] \n",
      "\tNext action: \"right\" to state 2 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 2:\n",
      "\tcurrent state: 2\n",
      "\tneighbor states: [('1', 'left'), ('3', 'right'), ('6', 'down')] \n",
      "\tneighbor states Q values: [0, 0, 0] \n",
      "\tNext action: \"down\" to state 6 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 3:\n",
      "\tcurrent state: 6\n",
      "\tneighbor states: [('2', 'up'), ('5', 'left'), ('7', 'right'), ('10', 'down')] \n",
      "\tneighbor states Q values: [0, 0, 0, 0] \n",
      "\tNext action: \"up\" to state 2 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 4:\n",
      "\tcurrent state: 2\n",
      "\tneighbor states: [('6', 'down'), ('1', 'left'), ('3', 'right')] \n",
      "\tneighbor states Q values: [-1.0, 0, 0] \n",
      "\tNext action: \"left\" to state 1 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 5:\n",
      "\tcurrent state: 1\n",
      "\tneighbor states: [('2', 'right'), ('5', 'down')] \n",
      "\tneighbor states Q values: [-1.0, 0] \n",
      "\tNext action: \"down\" to state 5 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 6:\n",
      "\tcurrent state: 5\n",
      "\tneighbor states: [('1', 'up'), ('6', 'right'), ('9', 'down')] \n",
      "\tneighbor states Q values: [0, 0, 0] \n",
      "\tNext action: \"down\" to state 9 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 7:\n",
      "\tcurrent state: 9\n",
      "\tneighbor states: [('5', 'up'), ('10', 'right'), ('13', 'down')] \n",
      "\tneighbor states Q values: [0, 0, 0] \n",
      "\tNext action: \"up\" to state 5 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 8:\n",
      "\tcurrent state: 5\n",
      "\tneighbor states: [('9', 'down'), ('1', 'up'), ('6', 'right')] \n",
      "\tneighbor states Q values: [-1.0, 0, 0] \n",
      "\tNext action: \"up\" to state 1 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 9:\n",
      "\tcurrent state: 1\n",
      "\tneighbor states: [('2', 'right'), ('5', 'down')] \n",
      "\tneighbor states Q values: [-1.0, -1.0] \n",
      "\tNext action: \"right\" to state 2 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 10:\n",
      "\tcurrent state: 2\n",
      "\tneighbor states: [('6', 'down'), ('1', 'left'), ('3', 'right')] \n",
      "\tneighbor states Q values: [-1.0, -1.0, 0] \n",
      "\tNext action: \"right\" to state 3 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 11:\n",
      "\tcurrent state: 3\n",
      "\tneighbor states: [('2', 'left'), ('4', 'right'), ('7', 'down')] \n",
      "\tneighbor states Q values: [0, 0, 0] \n",
      "\tNext action: \"left\" to state 2 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 12:\n",
      "\tcurrent state: 2\n",
      "\tneighbor states: [('6', 'down'), ('1', 'left'), ('3', 'right')] \n",
      "\tneighbor states Q values: [-1.0, -1.0, -1.0] \n",
      "\tNext action: \"down\" to state 6 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 13:\n",
      "\tcurrent state: 6\n",
      "\tneighbor states: [('2', 'up'), ('5', 'left'), ('7', 'right'), ('10', 'down')] \n",
      "\tneighbor states Q values: [-1.0, 0, 0, 0] \n",
      "\tNext action: \"left\" to state 5 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 14:\n",
      "\tcurrent state: 5\n",
      "\tneighbor states: [('9', 'down'), ('1', 'up'), ('6', 'right')] \n",
      "\tneighbor states Q values: [-1.0, -1.0, 0] \n",
      "\tNext action: \"right\" to state 6 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 15:\n",
      "\tcurrent state: 6\n",
      "\tneighbor states: [('2', 'up'), ('5', 'left'), ('7', 'right'), ('10', 'down')] \n",
      "\tneighbor states Q values: [-1.0, -1.0, 0, 0] \n",
      "\tNext action: \"right\" to state 7 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 16:\n",
      "\tcurrent state: 7\n",
      "\tneighbor states: [('3', 'up'), ('6', 'left'), ('8', 'right'), ('11', 'down')] \n",
      "\tneighbor states Q values: [0, 0, 0, 0] \n",
      "\tNext action: \"up\" to state 3 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 17:\n",
      "\tcurrent state: 3\n",
      "\tneighbor states: [('2', 'left'), ('4', 'right'), ('7', 'down')] \n",
      "\tneighbor states Q values: [-1.0, 0, 0] \n",
      "\tNext action: \"right\" to state 4 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 18:\n",
      "\tcurrent state: 4\n",
      "\tneighbor states: [('3', 'left'), ('8', 'down')] \n",
      "\tneighbor states Q values: [0, 0] \n",
      "\tNext action: \"left\" to state 3 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 19:\n",
      "\tcurrent state: 3\n",
      "\tneighbor states: [('2', 'left'), ('4', 'right'), ('7', 'down')] \n",
      "\tneighbor states Q values: [-1.0, -1.0, 0] \n",
      "\tNext action: \"left\" to state 2 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 20:\n",
      "\tcurrent state: 2\n",
      "\tneighbor states: [('6', 'down'), ('1', 'left'), ('3', 'right')] \n",
      "\tneighbor states Q values: [-1.5, -1.0, -1.0] \n",
      "\tNext action: \"left\" to state 1 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 21:\n",
      "\tcurrent state: 1\n",
      "\tneighbor states: [('2', 'right'), ('5', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.0] \n",
      "\tNext action: \"down\" to state 5 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.95\n",
      "Step 22:\n",
      "\tcurrent state: 5\n",
      "\tneighbor states: [('9', 'down'), ('1', 'up'), ('6', 'right')] \n",
      "\tneighbor states Q values: [-1.0, -1.0, -1.0] \n",
      "\tNext action: \"down\" to state 9 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 23:\n",
      "\tcurrent state: 9\n",
      "\tneighbor states: [('5', 'up'), ('10', 'right'), ('13', 'down')] \n",
      "\tneighbor states Q values: [-1.0, 0, 0] \n",
      "\tNext action: \"right\" to state 10 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 24:\n",
      "\tcurrent state: 10\n",
      "\tneighbor states: [('6', 'up'), ('9', 'left'), ('11', 'right'), ('14', 'down')] \n",
      "\tneighbor states Q values: [0, 0, 0, 0] \n",
      "\tNext action: \"up\" to state 6 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 25:\n",
      "\tcurrent state: 6\n",
      "\tneighbor states: [('2', 'up'), ('5', 'left'), ('7', 'right'), ('10', 'down')] \n",
      "\tneighbor states Q values: [-1.0, -1.0, -1.0, 0] \n",
      "\tNext action: \"down\" to state 10 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 26:\n",
      "\tcurrent state: 10\n",
      "\tneighbor states: [('6', 'up'), ('9', 'left'), ('11', 'right'), ('14', 'down')] \n",
      "\tneighbor states Q values: [-1.0, 0, 0, 0] \n",
      "\tNext action: \"left\" to state 9 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 27:\n",
      "\tcurrent state: 9\n",
      "\tneighbor states: [('5', 'up'), ('10', 'right'), ('13', 'down')] \n",
      "\tneighbor states Q values: [-1.0, -1.0, 0] \n",
      "\tNext action: \"down\" to state 13 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 28:\n",
      "\tcurrent state: 13\n",
      "\tneighbor states: [('9', 'up'), ('14', 'right')] \n",
      "\tneighbor states Q values: [0, 0] \n",
      "\tNext action: \"up\" to state 9 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 29:\n",
      "\tcurrent state: 9\n",
      "\tneighbor states: [('5', 'up'), ('10', 'right'), ('13', 'down')] \n",
      "\tneighbor states Q values: [-1.0, -1.0, -1.0] \n",
      "\tNext action: \"up\" to state 5 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 30:\n",
      "\tcurrent state: 5\n",
      "\tneighbor states: [('9', 'down'), ('1', 'up'), ('6', 'right')] \n",
      "\tneighbor states Q values: [-1.5, -1.0, -1.0] \n",
      "\tNext action: \"up\" to state 1 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 31:\n",
      "\tcurrent state: 1\n",
      "\tneighbor states: [('2', 'right'), ('5', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.95] \n",
      "\tNext action: \"down\" to state 5 with Q value = -1.95 and reward = -1\n",
      "\tUpdates Q value: -2.425\n",
      "Step 32:\n",
      "\tcurrent state: 5\n",
      "\tneighbor states: [('1', 'up'), ('6', 'right'), ('9', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.0, -1.5] \n",
      "\tNext action: \"right\" to state 6 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 33:\n",
      "\tcurrent state: 6\n",
      "\tneighbor states: [('2', 'up'), ('5', 'left'), ('7', 'right'), ('10', 'down')] \n",
      "\tneighbor states Q values: [-1.0, -1.0, -1.0, -1.0] \n",
      "\tNext action: \"up\" to state 2 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 34:\n",
      "\tcurrent state: 2\n",
      "\tneighbor states: [('6', 'down'), ('1', 'left'), ('3', 'right')] \n",
      "\tneighbor states Q values: [-1.5, -1.5, -1.0] \n",
      "\tNext action: \"down\" to state 6 with Q value = -1.5 and reward = -1\n",
      "\tUpdates Q value: -1.75\n",
      "Step 35:\n",
      "\tcurrent state: 6\n",
      "\tneighbor states: [('2', 'up'), ('5', 'left'), ('7', 'right'), ('10', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.0, -1.0, -1.0] \n",
      "\tNext action: \"left\" to state 5 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 36:\n",
      "\tcurrent state: 5\n",
      "\tneighbor states: [('6', 'right'), ('1', 'up'), ('9', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.5, -1.5] \n",
      "\tNext action: \"right\" to state 6 with Q value = -1.5 and reward = -1\n",
      "\tUpdates Q value: -1.75\n",
      "Step 37:\n",
      "\tcurrent state: 6\n",
      "\tneighbor states: [('2', 'up'), ('5', 'left'), ('7', 'right'), ('10', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.5, -1.0, -1.0] \n",
      "\tNext action: \"right\" to state 7 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 38:\n",
      "\tcurrent state: 7\n",
      "\tneighbor states: [('3', 'up'), ('6', 'left'), ('8', 'right'), ('11', 'down')] \n",
      "\tneighbor states Q values: [-1.0, 0, 0, 0] \n",
      "\tNext action: \"up\" to state 3 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 39:\n",
      "\tcurrent state: 3\n",
      "\tneighbor states: [('2', 'left'), ('4', 'right'), ('7', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.0, 0] \n",
      "\tNext action: \"down\" to state 7 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 40:\n",
      "\tcurrent state: 7\n",
      "\tneighbor states: [('3', 'up'), ('11', 'down'), ('6', 'left'), ('8', 'right')] \n",
      "\tneighbor states Q values: [-1.5, 0, 0, 0] \n",
      "\tNext action: \"down\" to state 11 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 41:\n",
      "\tcurrent state: 11\n",
      "\tneighbor states: [('7', 'up'), ('10', 'left'), ('12', 'right'), ('15', 'down')] \n",
      "\tneighbor states Q values: [0, 0, 0, 0] \n",
      "\tNext action: \"up\" to state 7 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 42:\n",
      "\tcurrent state: 7\n",
      "\tneighbor states: [('3', 'up'), ('11', 'down'), ('6', 'left'), ('8', 'right')] \n",
      "\tneighbor states Q values: [-1.5, -1.0, 0, 0] \n",
      "\tNext action: \"left\" to state 6 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 43:\n",
      "\tcurrent state: 6\n",
      "\tneighbor states: [('2', 'up'), ('5', 'left'), ('7', 'right'), ('10', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.5, -1.5, -1.0] \n",
      "\tNext action: \"down\" to state 10 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 44:\n",
      "\tcurrent state: 10\n",
      "\tneighbor states: [('9', 'left'), ('6', 'up'), ('11', 'right'), ('14', 'down')] \n",
      "\tneighbor states Q values: [-1.0, -1.0, 0, 0] \n",
      "\tNext action: \"left\" to state 9 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 45:\n",
      "\tcurrent state: 9\n",
      "\tneighbor states: [('5', 'up'), ('10', 'right'), ('13', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.0, -1.0] \n",
      "\tNext action: \"right\" to state 10 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 46:\n",
      "\tcurrent state: 10\n",
      "\tneighbor states: [('9', 'left'), ('11', 'right'), ('14', 'down'), ('6', 'up')] \n",
      "\tneighbor states Q values: [-1.5, 0, 0, -1.0] \n",
      "\tNext action: \"right\" to state 11 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 47:\n",
      "\tcurrent state: 11\n",
      "\tneighbor states: [('7', 'up'), ('10', 'left'), ('12', 'right'), ('15', 'down')] \n",
      "\tneighbor states Q values: [-1.0, 0, 0, 0] \n",
      "\tNext action: \"left\" to state 10 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 48:\n",
      "\tcurrent state: 10\n",
      "\tneighbor states: [('9', 'left'), ('11', 'right'), ('14', 'down'), ('6', 'up')] \n",
      "\tneighbor states Q values: [-1.5, -1.0, 0, -1.0] \n",
      "\tNext action: \"right\" to state 11 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 49:\n",
      "\tcurrent state: 11\n",
      "\tneighbor states: [('7', 'up'), ('10', 'left'), ('12', 'right'), ('15', 'down')] \n",
      "\tneighbor states Q values: [-1.0, -1.0, 0, 0] \n",
      "\tNext action: \"up\" to state 7 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 50:\n",
      "\tcurrent state: 7\n",
      "\tneighbor states: [('3', 'up'), ('11', 'down'), ('6', 'left'), ('8', 'right')] \n",
      "\tneighbor states Q values: [-1.5, -1.0, -1.0, 0] \n",
      "\tNext action: \"right\" to state 8 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 51:\n",
      "\tcurrent state: 8\n",
      "\tneighbor states: [('4', 'up'), ('7', 'left'), ('12', 'down')] \n",
      "\tneighbor states Q values: [0, 0, 0] \n",
      "\tNext action: \"up\" to state 4 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 52:\n",
      "\tcurrent state: 4\n",
      "\tneighbor states: [('3', 'left'), ('8', 'down')] \n",
      "\tneighbor states Q values: [-1.0, 0] \n",
      "\tNext action: \"left\" to state 3 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 53:\n",
      "\tcurrent state: 3\n",
      "\tneighbor states: [('2', 'left'), ('4', 'right'), ('7', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.0, -1.0] \n",
      "\tNext action: \"right\" to state 4 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 54:\n",
      "\tcurrent state: 4\n",
      "\tneighbor states: [('3', 'left'), ('8', 'down')] \n",
      "\tneighbor states Q values: [-1.5, 0] \n",
      "\tNext action: \"down\" to state 8 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 55:\n",
      "\tcurrent state: 8\n",
      "\tneighbor states: [('4', 'up'), ('7', 'left'), ('12', 'down')] \n",
      "\tneighbor states Q values: [-1.0, 0, 0] \n",
      "\tNext action: \"left\" to state 7 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 56:\n",
      "\tcurrent state: 7\n",
      "\tneighbor states: [('3', 'up'), ('11', 'down'), ('6', 'left'), ('8', 'right')] \n",
      "\tneighbor states Q values: [-1.5, -1.0, -1.0, -1.0] \n",
      "\tNext action: \"down\" to state 11 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 57:\n",
      "\tcurrent state: 11\n",
      "\tneighbor states: [('7', 'up'), ('12', 'right'), ('10', 'left'), ('15', 'down')] \n",
      "\tneighbor states Q values: [-1.5, 0, -1.0, 0] \n",
      "\tNext action: \"right\" to state 12 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 58:\n",
      "\tcurrent state: 12\n",
      "\tneighbor states: [('8', 'up'), ('11', 'left'), ('16', 'down')] \n",
      "\tneighbor states Q values: [0, 0, 0] \n",
      "\tNext action: \"up\" to state 8 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 59:\n",
      "\tcurrent state: 8\n",
      "\tneighbor states: [('4', 'up'), ('7', 'left'), ('12', 'down')] \n",
      "\tneighbor states Q values: [-1.0, -1.0, 0] \n",
      "\tNext action: \"up\" to state 4 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 60:\n",
      "\tcurrent state: 4\n",
      "\tneighbor states: [('3', 'left'), ('8', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.0] \n",
      "\tNext action: \"down\" to state 8 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 61:\n",
      "\tcurrent state: 8\n",
      "\tneighbor states: [('4', 'up'), ('12', 'down'), ('7', 'left')] \n",
      "\tneighbor states Q values: [-1.5, 0, -1.0] \n",
      "\tNext action: \"down\" to state 12 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 62:\n",
      "\tcurrent state: 12\n",
      "\tneighbor states: [('8', 'up'), ('11', 'left'), ('16', 'down')] \n",
      "\tneighbor states Q values: [-1.0, 0, 0] \n",
      "\tNext action: \"left\" to state 11 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 63:\n",
      "\tcurrent state: 11\n",
      "\tneighbor states: [('7', 'up'), ('12', 'right'), ('10', 'left'), ('15', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.0, -1.0, 0] \n",
      "\tNext action: \"up\" to state 7 with Q value = -1.5 and reward = -1\n",
      "\tUpdates Q value: -1.75\n",
      "Step 64:\n",
      "\tcurrent state: 7\n",
      "\tneighbor states: [('3', 'up'), ('11', 'down'), ('6', 'left'), ('8', 'right')] \n",
      "\tneighbor states Q values: [-1.5, -1.5, -1.0, -1.0] \n",
      "\tNext action: \"left\" to state 6 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 65:\n",
      "\tcurrent state: 6\n",
      "\tneighbor states: [('2', 'up'), ('5', 'left'), ('7', 'right'), ('10', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.5, -1.5, -1.5] \n",
      "\tNext action: \"down\" to state 10 with Q value = -1.5 and reward = -1\n",
      "\tUpdates Q value: -1.75\n",
      "Step 66:\n",
      "\tcurrent state: 10\n",
      "\tneighbor states: [('11', 'right'), ('9', 'left'), ('6', 'up'), ('14', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.5, -1.0, 0] \n",
      "\tNext action: \"down\" to state 14 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 67:\n",
      "\tcurrent state: 14\n",
      "\tneighbor states: [('10', 'up'), ('13', 'left'), ('15', 'right')] \n",
      "\tneighbor states Q values: [0, 0, 0] \n",
      "\tNext action: \"up\" to state 10 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 68:\n",
      "\tcurrent state: 10\n",
      "\tneighbor states: [('11', 'right'), ('9', 'left'), ('6', 'up'), ('14', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.5, -1.0, -1.0] \n",
      "\tNext action: \"up\" to state 6 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 69:\n",
      "\tcurrent state: 6\n",
      "\tneighbor states: [('10', 'down'), ('5', 'left'), ('7', 'right'), ('2', 'up')] \n",
      "\tneighbor states Q values: [-1.75, -1.5, -1.5, -1.5] \n",
      "\tNext action: \"left\" to state 5 with Q value = -1.5 and reward = -1\n",
      "\tUpdates Q value: -1.75\n",
      "Step 70:\n",
      "\tcurrent state: 5\n",
      "\tneighbor states: [('6', 'right'), ('1', 'up'), ('9', 'down')] \n",
      "\tneighbor states Q values: [-1.75, -1.5, -1.5] \n",
      "\tNext action: \"up\" to state 1 with Q value = -1.5 and reward = -1\n",
      "\tUpdates Q value: -1.75\n",
      "Step 71:\n",
      "\tcurrent state: 1\n",
      "\tneighbor states: [('5', 'down'), ('2', 'right')] \n",
      "\tneighbor states Q values: [-2.425, -1.5] \n",
      "\tNext action: \"right\" to state 2 with Q value = -1.5 and reward = -1\n",
      "\tUpdates Q value: -2.2\n",
      "Step 72:\n",
      "\tcurrent state: 2\n",
      "\tneighbor states: [('6', 'down'), ('1', 'left'), ('3', 'right')] \n",
      "\tneighbor states Q values: [-1.75, -1.5, -1.0] \n",
      "\tNext action: \"right\" to state 3 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 73:\n",
      "\tcurrent state: 3\n",
      "\tneighbor states: [('2', 'left'), ('4', 'right'), ('7', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.5, -1.0] \n",
      "\tNext action: \"down\" to state 7 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 74:\n",
      "\tcurrent state: 7\n",
      "\tneighbor states: [('6', 'left'), ('3', 'up'), ('8', 'right'), ('11', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.5, -1.0, -1.5] \n",
      "\tNext action: \"up\" to state 3 with Q value = -1.5 and reward = -1\n",
      "\tUpdates Q value: -1.75\n",
      "Step 75:\n",
      "\tcurrent state: 3\n",
      "\tneighbor states: [('2', 'left'), ('4', 'right'), ('7', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.5, -1.5] \n",
      "\tNext action: \"left\" to state 2 with Q value = -1.5 and reward = -1\n",
      "\tUpdates Q value: -1.75\n",
      "Step 76:\n",
      "\tcurrent state: 2\n",
      "\tneighbor states: [('3', 'right'), ('1', 'left'), ('6', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.5, -1.75] \n",
      "\tNext action: \"right\" to state 3 with Q value = -1.5 and reward = -1\n",
      "\tUpdates Q value: -1.75\n",
      "Step 77:\n",
      "\tcurrent state: 3\n",
      "\tneighbor states: [('2', 'left'), ('4', 'right'), ('7', 'down')] \n",
      "\tneighbor states Q values: [-1.75, -1.5, -1.5] \n",
      "\tNext action: \"right\" to state 4 with Q value = -1.5 and reward = -1\n",
      "\tUpdates Q value: -1.75\n",
      "Step 78:\n",
      "\tcurrent state: 4\n",
      "\tneighbor states: [('3', 'left'), ('8', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.5] \n",
      "\tNext action: \"left\" to state 3 with Q value = -1.5 and reward = -1\n",
      "\tUpdates Q value: -2.2\n",
      "Step 79:\n",
      "\tcurrent state: 3\n",
      "\tneighbor states: [('2', 'left'), ('4', 'right'), ('7', 'down')] \n",
      "\tneighbor states Q values: [-1.75, -1.75, -1.5] \n",
      "\tNext action: \"down\" to state 7 with Q value = -1.5 and reward = -1\n",
      "\tUpdates Q value: -1.75\n",
      "Step 80:\n",
      "\tcurrent state: 7\n",
      "\tneighbor states: [('3', 'up'), ('11', 'down'), ('8', 'right'), ('6', 'left')] \n",
      "\tneighbor states Q values: [-1.75, -1.5, -1.0, -1.5] \n",
      "\tNext action: \"right\" to state 8 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 81:\n",
      "\tcurrent state: 8\n",
      "\tneighbor states: [('4', 'up'), ('12', 'down'), ('7', 'left')] \n",
      "\tneighbor states Q values: [-1.5, -1.0, -1.0] \n",
      "\tNext action: \"left\" to state 7 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 82:\n",
      "\tcurrent state: 7\n",
      "\tneighbor states: [('3', 'up'), ('11', 'down'), ('8', 'right'), ('6', 'left')] \n",
      "\tneighbor states Q values: [-1.75, -1.5, -1.5, -1.5] \n",
      "\tNext action: \"down\" to state 11 with Q value = -1.5 and reward = -1\n",
      "\tUpdates Q value: -1.75\n",
      "Step 83:\n",
      "\tcurrent state: 11\n",
      "\tneighbor states: [('7', 'up'), ('15', 'down'), ('12', 'right'), ('10', 'left')] \n",
      "\tneighbor states Q values: [-1.75, 0, -1.0, -1.0] \n",
      "\tNext action: \"down\" to state 15 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 84:\n",
      "\tcurrent state: 15\n",
      "\tneighbor states: [('11', 'up'), ('14', 'left'), ('16', 'right')] \n",
      "\tneighbor states Q values: [0, 0, 0] \n",
      "\tNext action: \"up\" to state 11 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 85:\n",
      "\tcurrent state: 11\n",
      "\tneighbor states: [('7', 'up'), ('15', 'down'), ('12', 'right'), ('10', 'left')] \n",
      "\tneighbor states Q values: [-1.75, -1.0, -1.0, -1.0] \n",
      "\tNext action: \"down\" to state 15 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 86:\n",
      "\tcurrent state: 15\n",
      "\tneighbor states: [('11', 'up'), ('14', 'left'), ('16', 'right')] \n",
      "\tneighbor states Q values: [-1.0, 0, 0] \n",
      "\tNext action: \"left\" to state 14 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 87:\n",
      "\tcurrent state: 14\n",
      "\tneighbor states: [('10', 'up'), ('13', 'left'), ('15', 'right')] \n",
      "\tneighbor states Q values: [-1.0, 0, 0] \n",
      "\tNext action: \"up\" to state 10 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 88:\n",
      "\tcurrent state: 10\n",
      "\tneighbor states: [('11', 'right'), ('9', 'left'), ('6', 'up'), ('14', 'down')] \n",
      "\tneighbor states Q values: [-1.5, -1.5, -1.5, -1.0] \n",
      "\tNext action: \"down\" to state 14 with Q value = -1.0 and reward = -1\n",
      "\tUpdates Q value: -1.5\n",
      "Step 89:\n",
      "\tcurrent state: 14\n",
      "\tneighbor states: [('10', 'up'), ('13', 'left'), ('15', 'right')] \n",
      "\tneighbor states Q values: [-1.5, 0, 0] \n",
      "\tNext action: \"left\" to state 13 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 90:\n",
      "\tcurrent state: 13\n",
      "\tneighbor states: [('9', 'up'), ('14', 'right')] \n",
      "\tneighbor states Q values: [-1.0, 0] \n",
      "\tNext action: \"right\" to state 14 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 91:\n",
      "\tcurrent state: 14\n",
      "\tneighbor states: [('10', 'up'), ('13', 'left'), ('15', 'right')] \n",
      "\tneighbor states Q values: [-1.5, -1.0, 0] \n",
      "\tNext action: \"right\" to state 15 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 92:\n",
      "\tcurrent state: 15\n",
      "\tneighbor states: [('11', 'up'), ('14', 'left'), ('16', 'right')] \n",
      "\tneighbor states Q values: [-1.0, -1.0, 0] \n",
      "\tNext action: \"right\" to state 16 with Q value = 0 and reward = -1\n",
      "\tUpdates Q value: -1.0\n",
      "Step 93:\n",
      "\tcurrent state: 16\n",
      "Goal state found at 93 iteration\n"
     ]
    }
   ],
   "source": [
    "current_state = \"1\"\n",
    "states_follow_up = [current_state]\n",
    "\n",
    "\n",
    "for i in range(1_000):\n",
    "    print(f\"Step {i+1}:\")\n",
    "    print(f\"\\tcurrent state: {current_state}\")\n",
    "\n",
    "    if current_state == \"16\":\n",
    "        print(f\"Goal state found at {i+1} iteration\")\n",
    "        break\n",
    "\n",
    "    neighbor_states = get_neighbor_states(state=current_state)\n",
    "    neighbor_states_Q = get_neighbor_states_Q(\n",
    "        current_state=current_state, neighbor_states=neighbor_states\n",
    "    )\n",
    "\n",
    "    print(f\"\\tneighbor states: {neighbor_states} \")\n",
    "    print(f\"\\tneighbor states Q values: {neighbor_states_Q} \")\n",
    "\n",
    "    # next_state = get_next_state(\n",
    "    #     current_state=current_state, neighbor_states=neighbor_states\n",
    "    # )\n",
    "    next_state = choose_action(current_state=current_state, neighbor_states=neighbor_states, epsilon=.3)\n",
    "    \n",
    "    next_action_state_Q = get_state_Q(state=current_state, action=next_state[1])\n",
    "    next_state_reward = get_reward(next_state[0])\n",
    "    print(\n",
    "        f'\\tNext action: \"{next_state[1]}\" to state {next_state[0]} with Q value = {next_action_state_Q} and reward = {next_state_reward}'\n",
    "    )\n",
    "\n",
    "    updated_Q = get_Q_update(\n",
    "        state_Q=next_action_state_Q,\n",
    "        state_reward=next_state_reward,\n",
    "        neighbor_states=neighbor_states,\n",
    "        learning_rate=0.5,\n",
    "        discount_factor=0.9,\n",
    "        step_penalty=-1,\n",
    "    )\n",
    "\n",
    "    set_state_Q(state=current_state, action=next_state[1], new_value=updated_Q)\n",
    "    print(\n",
    "        f\"\\tUpdates Q value: {get_state_Q(state=current_state, action=next_state[1])}\"\n",
    "    )\n",
    "\n",
    "    current_state = next_state[0]\n",
    "    states_follow_up.append(current_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
